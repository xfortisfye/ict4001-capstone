{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff04440-8080-4635-ac32-430ac6f7eff4",
   "metadata": {},
   "source": [
    "#### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af71c6bf-604a-4f0c-a18c-6f91bbcf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform\n",
    "import py7zr\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, \\\n",
    "    BatchNormalization, Flatten, LSTM\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45a7c3",
   "metadata": {},
   "source": [
    "#### PARAMETERS\n",
    "- Set the condition\n",
    "> * N_FEATURES: Number of Features\n",
    "> * CHECK_BLANKS: Check for blank data. If any blank data is found, the whole row of data will be deleted.\n",
    "> * CHECK_CLASS_IMBALANCE: Check for dataset class imbalance. The more balance the dataset, the less biases the model will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7460824",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ACTUAL_DATASET_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 59>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m DATASET_DIR_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), DATASET_DIR_NAME)\n\u001b[0;32m     58\u001b[0m SAMPLE_DATASET_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATASET_DIR_PATH, SAMPLE_DATASET_NAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m ACTUAL_DATASET_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATASET_DIR_PATH, \u001b[43mACTUAL_DATASET_NAME\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m MODEL_DIR_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), MODEL_DIR_NAME)\n\u001b[0;32m     62\u001b[0m MODEL_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_DIR_PATH, MODEL_NAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ACTUAL_DATASET_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# # deep learning features # #\n",
    "##############################\n",
    "SEED = 1005 # random seed for reproducibility\n",
    "\n",
    "# should make this dynamic\n",
    "N_FEATURES = 644\n",
    "TIMESTEPS = 1\n",
    "EPOCH=200\n",
    "BATCH_SIZE=100\n",
    "\n",
    "SPLIT_RATIO=0.2\n",
    "\n",
    "###############\n",
    "# # preview # #\n",
    "###############\n",
    "f = False\n",
    "t = True\n",
    "\n",
    "# checking dataset\n",
    "CHECK_BLANKS = True\n",
    "CHECK_CLASS_IMBALANCE = True\n",
    "\n",
    "# evaluate suitable kfold number and kfold model\n",
    "MIN_KFOLD = 2\n",
    "MAX_KFOLD = 11\n",
    "N_KFOLD = 5\n",
    "EVAL_KFOLD_NUM = False\n",
    "EVAL_KFOLD_MODEL = False\n",
    "PERFORM_KFOLD = False\n",
    "\n",
    "# model testing\n",
    "TEST_MODEL = True\n",
    "CON_MATRIX = True\n",
    "ROC_GRAPH = True\n",
    "\n",
    "###############\n",
    "# # dataset # #\n",
    "###############\n",
    "CLASSES_COL_NAME = \"Subject\"\n",
    "CLASSES_COL_NUM = 0\n",
    "FEATURES_COL_NUM = 3\n",
    "\n",
    "# METHOD = \"IU\"\n",
    "# METHOD = \"DU\"\n",
    "\n",
    "DATASET_DIR_NAME = \"dataset\\set02\\\\02_pair\"\n",
    "SAMPLE_DATASET_NAME = \"pair_train\"\n",
    "# ACTUAL_DATASET_NAME = \"pair_test_\" + METHOD\n",
    "\n",
    "MODEL_DIR_NAME = \"dataset\\set02\\\\02_pair\"\n",
    "MODEL_NAME = \"model_\" + \"set02_02_pair\"\n",
    "\n",
    "# RESULT_DIR_NAME = \"dataset\\set02\\\\02_pair\"\n",
    "# RESULT_NAME = \"result_\" + \"set02_02_pair_\" + METHOD\n",
    "\n",
    "DATASET_DIR_PATH = os.path.join(os.getcwd(), DATASET_DIR_NAME)\n",
    "SAMPLE_DATASET_PATH = os.path.join(DATASET_DIR_PATH, SAMPLE_DATASET_NAME + \".csv\")\n",
    "# ACTUAL_DATASET_PATH = os.path.join(DATASET_DIR_PATH, ACTUAL_DATASET_NAME + \".csv\")\n",
    "\n",
    "MODEL_DIR_PATH = os.path.join(os.getcwd(), MODEL_DIR_NAME)\n",
    "MODEL_PATH = os.path.join(MODEL_DIR_PATH, MODEL_NAME + \".h5\")\n",
    "\n",
    "# RESULT_DIR_PATH = os.path.join(os.getcwd(), RESULT_DIR_NAME)\n",
    "# RESULT_PATH = os.path.join(RESULT_DIR_PATH, RESULT_NAME + \".csv\")\n",
    "\n",
    "#################\n",
    "# # sns theme # #\n",
    "#################\n",
    "# sns.set_theme(style=\"darkgrid\") # (dark background with white gridlines)\n",
    "sns.set_theme(style=\"whitegrid\") # (white background with grey gridlines)\n",
    "# sns.set_theme(style=\"dark\") # (dark background with no gridlines)\n",
    "# sns.set_theme(style=\"white\") # (white background with no gridlines)\n",
    "# sns.set_theme(style=\"ticks\") # (white background with axis ticks and no gridlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b4aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isdir(DATASET_DIR_PATH) is True:\n",
    "    print(f\"Dataset directory exists at: {DATASET_DIR_PATH}\")\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(DATASET_DIR_PATH, 666)\n",
    "        print(f\"Dataset directory have been created at: {DATASET_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Dataset Directory not created\")\n",
    "        \n",
    "if os.path.isdir(MODEL_DIR_PATH) is True:\n",
    "    print(f\"Model directory exists at: {MODEL_DIR_PATH}\")\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(MODEL_DIR_PATH, 666)\n",
    "        print(f\"Model directory have been created at: {MODEL_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Model Directory not created\")\n",
    "    \n",
    "if os.path.exists(SAMPLE_DATASET_PATH) is True:\n",
    "    print(f\"Training dataset exists at: {SAMPLE_DATASET_PATH}\")\n",
    "else:\n",
    "    try:\n",
    "        SAMPLE_7Z_PATH = os.path.join(DATASET_DIR_PATH, SAMPLE_DATASET_NAME + \".7z\")\n",
    "        with py7zr.SevenZipFile(SAMPLE_7Z_PATH, mode='r') as z:\n",
    "            z.extractall(path=DATASET_DIR_PATH)\n",
    "        print(f\"Decompress 7z file to: {SAMPLE_7Z_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Failed to decompress 7z file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52cdd5",
   "metadata": {},
   "source": [
    "#### CREATE MODEL\n",
    "- Create base model\n",
    "- Wrap it with KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f633b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create base model\n",
    "def create_base_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=256, return_sequences=True,\n",
    "             input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "    model.add(Dense(256, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dense(128, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dense(64, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=32, return_sequences=True))\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # softmax for multi-class classification\n",
    "    model.add(Flatten())\n",
    "    print(\"There are a total of \" + str(n_classes) + \" classes.\")\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# wrap model in KerasClassifier\n",
    "def create_model():\n",
    "    model = KerasClassifier(build_fn=create_base_model, epochs=EPOCH, \n",
    "                            batch_size=BATCH_SIZE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2280ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into features X and target (classes) Y\n",
    "def prepare_dataset(df):\n",
    "    X = df.values[:,FEATURES_COL_NUM:].astype(float)\n",
    "    Y = df.values[:,CLASSES_COL_NUM].astype(str)\n",
    "\n",
    "    # convert target Y to labelbinarizer Y for model\n",
    "    # fit_transform is not used to reuse lb\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    lb = LabelBinarizer().fit(Y)\n",
    "    Y = lb.transform(Y)\n",
    "\n",
    "    #################################\n",
    "    # # get all the encoded class # #\n",
    "    #################################\n",
    "    print(\"LabelBinarizer is able to decipher: \")\n",
    "    print(lb.classes_)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ###########################\n",
    "    # # print X and Y shape # #\n",
    "    ###########################\n",
    "    print(f\"X | Features | Dataset Shape: {X.shape}\")\n",
    "    print(f\"Y | Classes  | Dataset Shape: {Y.shape}\")\n",
    "\n",
    "    return X, Y, lb, lb.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_shape_dataset(X, Y, SPLIT_RATIO, TIMESTEPS, SEED):\n",
    "\n",
    "    ##############################################################\n",
    "    # # split dataset into train and test set of 0.8/0.2 ratio # #\n",
    "    ##############################################################\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=SPLIT_RATIO, random_state=SEED)\n",
    "\n",
    "    ############################\n",
    "    # # reshaping of dataset # #\n",
    "    ############################\n",
    "\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], TIMESTEPS, X_train.shape[1]))\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], TIMESTEPS, X_test.shape[1]))\n",
    "\n",
    "    print(f\"X train shape: {X_train.shape}\")\n",
    "    print(f\"Y train shape: {y_train.shape}\")\n",
    "    print(f\"X test shape: {X_test.shape}\")\n",
    "    print(f\"Y test shape: {y_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def reshape_dataset(X, TIMESTEPS):\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    X = np.reshape(X, (X.shape[0], TIMESTEPS, X.shape[1]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244ab5e",
   "metadata": {},
   "source": [
    "#### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13daa1c",
   "metadata": {},
   "source": [
    "#### CHECK DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# # check for blanks # #\n",
    "########################\n",
    "if CHECK_BLANKS is True:\n",
    "    # checking for blanks\n",
    "    print(\"Checking for blanks...\")\n",
    "    if df.isnull().values.any() is True:\n",
    "        df = df.dropna(axis=0, how=\"any\")\n",
    "        print(\"Blank rows has been dropped.\")\n",
    "    else:\n",
    "        print(\"No blank value has been found.\")\n",
    "        \n",
    "#################################\n",
    "# # check for class imbalance # #\n",
    "#################################\n",
    "if CHECK_CLASS_IMBALANCE is True:\n",
    "    print(\"Checking for class imbalance...\")\n",
    "    sns.countplot(x=CLASSES_COL_NAME, data=df).set_title(\"Class Imbalance\")\n",
    "#     df.loc[(df!=0).any(axis=1)]\n",
    "    plt.show()\n",
    "\n",
    "sns.catplot(x=\"Subject\", y=\"T2-D|0\", hue=\"T2-D|0\", data=df, legend=False)\n",
    "sns.catplot(x=\"Subject\", y=\"T2-I|0+1\", hue=\"T2-I|0+1\", data=df, legend=False)\n",
    "sns.catplot(x=\"Subject\", y=\"T2-PF|0+1\", hue=\"T2-PF|0+1\", data=df, legend=False)\n",
    "sns.catplot(x=\"Subject\", y=\"T2-RF|0+1\", hue=\"T2-RF|0+1\", data=df, legend=False)\n",
    "sns.catplot(x=\"Subject\", y=\"T2-D|1\", hue=\"T2-D|1\", data=df, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9b784",
   "metadata": {},
   "source": [
    "#### PREPARE DATASET\n",
    "- Split data based on X / Features and Y / Classes\n",
    "- Binarize Y into binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, lb, class_list = prepare_dataset(df)\n",
    "n_classes = len(class_list)\n",
    "print(f\"Number of Classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fbc1a",
   "metadata": {},
   "source": [
    "#### SPLIT DATASET\n",
    "- Split dataset into train set and test set 0.8 / 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f4106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# # split dataset into train and test set of 0.8/0.2 ratio # #\n",
    "##############################################################\n",
    "X_train, X_test, y_train, y_test = split_shape_dataset(X, Y, SPLIT_RATIO, TIMESTEPS, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3cb08",
   "metadata": {},
   "source": [
    "#### PERFORM VALIDATION (w KFold Validation)\n",
    "- Evaluate best KFold Validation\n",
    "- Generate loss and accuracy graph\n",
    "- Perform KFold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54349ee1",
   "metadata": {},
   "source": [
    "##### Evaluate suitable folds for kfold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ec946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "# # evaluate suitable kfold value for model # #\n",
    "###############################################\n",
    "def evaluate_kfold(X_train, y_train, SEED, MIN_KFOLD, MAX_KFOLD):\n",
    "    \n",
    "    # evaluate the model    \n",
    "    folds = range(MIN_KFOLD, MAX_KFOLD)\n",
    "    means, mins, maxs = list(), list(), list()\n",
    "    \n",
    "    # evaluate each k value\n",
    "    for k in folds:\n",
    "        # define the test condition\n",
    "        kfold = KFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        # evaluate k value\n",
    "        model = create_model()\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=kfold, n_jobs=-1)\n",
    "        \n",
    "        k_mean = np.mean(scores)\n",
    "        k_min = scores.min()\n",
    "        k_max = scores.max()\n",
    "        \n",
    "        # report performance\n",
    "        print(f\"No. of Folds: {k} | Accuracy: {k_mean*100:.3f} | Min: {k_min*100:.3f} | Max: {k_max*100:.3f}\")\n",
    "        \n",
    "        # store mean accuracy and min and max relative to the mean\n",
    "        means.append(k_mean)\n",
    "        mins.append(k_mean - k_min)\n",
    "        maxs.append(k_max - k_mean)\n",
    "        \n",
    "    # line plot of k mean values with min/max error bars\n",
    "    clear_output(wait=True)\n",
    "    pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "    \n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "    \n",
    "if EVAL_KFOLD_NUM is True:\n",
    "    evaluate_kfold(X_train, y_train, SEED, MIN_KFOLD, MAX_KFOLD)\n",
    "else:\n",
    "    print(\"EVAL_KFOLD_NUM is not True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d290e",
   "metadata": {},
   "source": [
    "##### Generate kfold validation accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# # evaluate kfold model for accuracy and loss # #\n",
    "##################################################\n",
    "def evaluate_kfold_model(X_train, y_train, SEED):\n",
    "    scores, histories = list(), list()\n",
    "    # create model\n",
    "    model = create_model()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(X_train):\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = X_train[train_ix], y_train[train_ix], X_train[test_ix], y_train[test_ix]\n",
    "        # fit model\n",
    "        history = model.fit(trainX, trainY, epochs=100, batch_size=50, validation_data=(testX, testY), verbose=0)\n",
    "        \n",
    "        # evaluate model\n",
    "        y_pred = model.predict(testX)\n",
    "        y_pred = to_categorical(y_pred)\n",
    "\n",
    "        # evaluate predictions\n",
    "        acc = accuracy_score(testY, y_pred)\n",
    "        print(\"Testing accuracy: %.3f%%\" % (acc*100))\n",
    "\n",
    "        # stores scores and histories\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        f1 = plt.figure(1)\n",
    "        plt.title('Categorical Cross-Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'], color='blue')\n",
    "        plt.plot(histories[i].history['val_loss'], color='orange')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "        # plot accuracy\n",
    "        f2 = plt.figure(2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['accuracy'], color='blue')\n",
    "        plt.plot(histories[i].history['val_accuracy'], color='orange')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "    # print summary\n",
    "    print(f\"Accuracy | Mean: {np.mean(scores)*100:.3f} | Std: {np.std(scores)*100:.3f} | Length/no.: {len(scores)}\")\n",
    "    # box and whisker plots of results\n",
    "    f3 = plt.figure(3)\n",
    "    plt.title('Box and Whisker Plot of Accuracy Scores')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('model')\n",
    "    plt.boxplot(scores)\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    \n",
    "if EVAL_KFOLD_MODEL is True:\n",
    "    evaluate_kfold_model(X_train, y_train, SEED)\n",
    "else:\n",
    "    print(\"EVAL_KFOLD_MODEL is not true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7133b",
   "metadata": {},
   "source": [
    "##### Perform Actual KFold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411e204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if PERFORM_KFOLD is True:\n",
    "    # create model\n",
    "    model = create_model()\n",
    "    kfold = KFold(n_splits=N_KFOLD, shuffle=True, random_state=SEED)\n",
    "    valid_score = cross_val_score(model, X_train, y_train, \n",
    "                          cv=kfold, error_score=\"raise\", verbose=0)\n",
    "else:\n",
    "    print(\"PERFORM_KFOLD is not true.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474856b9",
   "metadata": {},
   "source": [
    "##### Get Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERFORM_KFOLD is True:\n",
    "    print(\"Validation Accuracy of %.2f%% (with standard deviation of %.2f%%)\" % \n",
    "      (valid_score.mean()*100, valid_score.std()*100))\n",
    "else:\n",
    "    print(\"PERFORM_KFOLD is not true.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18643ec",
   "metadata": {},
   "source": [
    "#### FIT MODEL FOR TESTING\n",
    "- Fit the Model\n",
    "- View Accuracy and Loss Graph\n",
    "- View Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2f15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "# # fit the model # #\n",
    "#####################\n",
    "\n",
    "if TEST_MODEL is True:\n",
    "    model = create_model()\n",
    "    es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
    "                       verbose=1)\n",
    "    history = model.fit(X_train, y_train, callbacks=es, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c058a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True:\n",
    "    ##########################\n",
    "    # # get model accuracy # #\n",
    "    ##########################\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    ######################\n",
    "    # # get model loss # #\n",
    "    ######################\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True:\n",
    "    ##########################\n",
    "    # # view model summary # #\n",
    "    ##########################\n",
    "    model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a64780",
   "metadata": {},
   "source": [
    "#### MODEL TESTING\n",
    "- Get Model Accuracy on the Test Dataset\n",
    "- Generate Confusion Matrix\n",
    "- Generate ROC Curves\n",
    "- Save the Model if Appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda705c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True:\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "\n",
    "    # evaluate predictions\n",
    "    acc = accuracy_score(lb.inverse_transform(y_test), lb.inverse_transform(y_pred))\n",
    "    print(\"Testing accuracy: %.3f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db889b",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6068e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and CON_MATRIX is True:\n",
    "    # confusion matrix\n",
    "    print(str(len(y_pred)) + \" is the number of test value in kfold_val / train_test_split\")\n",
    "    cm = confusion_matrix(lb.inverse_transform(y_test), lb.inverse_transform(y_pred))\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in np.unique(lb.inverse_transform(y_test))],\n",
    "                         columns = [i for i in np.unique(lb.inverse_transform(y_test))])\n",
    "\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=True, cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9a1f8",
   "metadata": {},
   "source": [
    "##### ROC Curve (Individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77dae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and ROC_GRAPH is True: # compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=\"darkorange\",\n",
    "            lw=lw,\n",
    "            label=\"ROC curve (area = %0.2f)\" % roc_auc[i],\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "        plt.xlim([-0.005, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve (\" + str(lb.classes_[i]) + \")\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53449bd8",
   "metadata": {},
   "source": [
    "##### ROC Curve (Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and ROC_GRAPH is True:\n",
    "    # compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], thresholds = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # first aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    # plt.figure()\n",
    "    # plt.plot(\n",
    "    #     fpr[\"micro\"],\n",
    "    #     tpr[\"micro\"],\n",
    "    #     label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    #     color=\"deeppink\",\n",
    "    #     linestyle=\":\",\n",
    "    #     linewidth=4,\n",
    "    # )\n",
    "\n",
    "    # plt.plot(\n",
    "    #     fpr[\"macro\"],\n",
    "    #     tpr[\"macro\"],\n",
    "    #     label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    #     color=\"navy\",\n",
    "    #     linestyle=\":\",\n",
    "    #     linewidth=4,\n",
    "    # )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"lightgreen\", \"purple\"])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=color,\n",
    "            lw=lw,\n",
    "            label=\"ROC curve of class {0} (area = {1:0.2f})\".format(lb.classes_[i], roc_auc[i]),\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "    plt.xlim([-0.005, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve (Multiclass)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd4e12",
   "metadata": {},
   "source": [
    "##### ROC Curve (Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf917af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODEL is True and ROC_GRAPH is True:\n",
    "    fpr, tpr, threshold = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "\n",
    "    # calculate equal-error-rate\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='AUC = {:.3f}, EER = {:.3f}'.format(auc(fpr, tpr), eer))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('Average ROC Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b17bde",
   "metadata": {},
   "source": [
    "#### FIT AND SAVE MODEL\n",
    "- Fitting of model\n",
    "- Get Accuracy and Loss of Mdoel\n",
    "- Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5703966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# # reshaping of dataset # #\n",
    "############################\n",
    "# loading of dataset\n",
    "df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "\n",
    "df.head()\n",
    "dataset = df.values\n",
    "\n",
    "# divide data into features X and target (classes) Y\n",
    "# convert target Y to labelbinarizer Y for model\n",
    "X, Y, lb, class_list = prepare_dataset(df)\n",
    "\n",
    "# reshaping the dataset to include LSTM Timesteps\n",
    "X = reshape_dataset(X, TIMESTEPS)\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "#####################\n",
    "# # fit the model # #\n",
    "#####################\n",
    "\n",
    "model = create_model()\n",
    "es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
    "                   verbose=0)\n",
    "history = model.fit(X, Y, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1771e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# # get model accuracy # #\n",
    "##########################\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "######################\n",
    "# # get model loss # #\n",
    "######################\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d2413",
   "metadata": {},
   "source": [
    "#### SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # save model # #\n",
    "##################\n",
    "model.model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799eac",
   "metadata": {},
   "source": [
    "# LIVE TESTING FOR IU\n",
    "> Live test with new dataset to check if model function as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0074460",
   "metadata": {},
   "source": [
    "#### LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da540d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # load model # #\n",
    "##################\n",
    "\n",
    "# model = create_model()\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f0646",
   "metadata": {},
   "source": [
    "#### LOAD DATA\n",
    "- Import new dataset to verify the model is able to predict accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bff51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = \"IU\" # identical_unique\n",
    "# METHOD = \"DU\" # different_unique\n",
    "\n",
    "DATASET_DIR_NAME = \"dataset\\set02\\\\02_pair\"\n",
    "ACTUAL_DATASET_NAME = \"pair_test_\" + METHOD\n",
    "ACTUAL_DATASET_PATH = os.path.join(DATASET_DIR_PATH, ACTUAL_DATASET_NAME + \".csv\")\n",
    "\n",
    "RESULT_DIR_NAME = \"dataset\\set02\\\\02_pair\"\n",
    "RESULT_NAME = \"result_\" + \"set02_02_pair_\" + METHOD\n",
    "RESULT_DIR_PATH = os.path.join(os.getcwd(), RESULT_DIR_NAME)\n",
    "RESULT_PATH = os.path.join(RESULT_DIR_PATH, RESULT_NAME + \".csv\")\n",
    "\n",
    "# import unseen data\n",
    "pred_df = pd.read_csv(ACTUAL_DATASET_PATH)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# # check for class validity # #\n",
    "################################\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"Subject\", data=pred_df).set_title(\"Class Validity\")\n",
    "\n",
    "# remove missing values if available\n",
    "pred_df = pred_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b061d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = pred_df.values\n",
    "actual_np = pred_dataset[:,CLASSES_COL_NUM]\n",
    "\n",
    "# # divide data into features X\n",
    "# pred_row = pred_dataset[:,3:].astype(float)\n",
    "\n",
    "########################\n",
    "# # predict all rows # #\n",
    "########################\n",
    "pred_row=pred_df.iloc[:,FEATURES_COL_NUM:]\n",
    "\n",
    "#################################\n",
    "# # predict more than one row # #\n",
    "#################################\n",
    "\n",
    "# pred_row=pred_df.iloc[46:54,FEATURES_COL_NUM:]\n",
    "# print(pred_row)\n",
    "\n",
    "############################\n",
    "# # predict a single row # #\n",
    "############################\n",
    "\n",
    "# pred_row=pred_df.iloc[11:12,FEATURES_COL_NUM:]\n",
    "\n",
    "##################\n",
    "# # shape data # #\n",
    "##################\n",
    "pred_row = pred_row.values.tolist()\n",
    "pred_arr = np.asarray(pred_row, dtype=np.float32)\n",
    "pred_arr = np.reshape(pred_arr, (pred_arr.shape[0], TIMESTEPS, pred_arr.shape[1]))\n",
    "\n",
    "print(class_list)\n",
    "Y = np.asarray(class_list)\n",
    "Y = Y.reshape(-1, 1)\n",
    "lb = LabelBinarizer().fit(Y)\n",
    "Y = lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad543869",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# # get prediction and its label # #\n",
    "####################################\n",
    "\n",
    "pred_proba = model.predict(pred_arr)\n",
    "\n",
    "# pred_proba = np.sum(pred_proba, axis=0)\n",
    "# pred_proba = np.reshape(pred_proba, (1, 9))\n",
    "\n",
    "pred = lb.inverse_transform(pred_proba)\n",
    "acc = np.max(pred_proba, axis=1)\n",
    "\n",
    "match_list = []\n",
    "\n",
    "for _ in range(actual_np.size):\n",
    "    if pred[_] == actual_np[_]:\n",
    "        match_list.append(\"match\")\n",
    "    else:\n",
    "        match_list.append(\"nope\")\n",
    "\n",
    "match_count = match_list.count(\"match\")\n",
    "total_count = len(match_list)\n",
    "\n",
    "match_header = str(match_count) + \"/\" + str(total_count) + \" (\" + str(match_count/total_count*100)+ \"%)\"\n",
    "match_np = np.array(match_list)\n",
    "\n",
    "exported_output = np.column_stack((actual_np, pred))\n",
    "exported_output = np.column_stack((exported_output, acc))\n",
    "exported_output = np.column_stack((exported_output, match_np))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.DataFrame(data=exported_output, index=None, columns=['Actual', 'Prediction', 'Accuracy', match_header])\n",
    "# print(df)\n",
    "df.to_csv(RESULT_PATH)\n",
    "\n",
    "print(\"Accuracy of the Model is: \" + str(match_header))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72442c",
   "metadata": {},
   "source": [
    "# LIVE TESTING FOR DU\n",
    "> Live test with new dataset to check if model function as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55621e1",
   "metadata": {},
   "source": [
    "#### LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40257086",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # load model # #\n",
    "##################\n",
    "\n",
    "# model = create_model()\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb11ba",
   "metadata": {},
   "source": [
    "#### LOAD DATA\n",
    "- Import new dataset to verify the model is able to predict accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD = \"IU\" # identical_unique\n",
    "METHOD = \"DU\" # different_unique\n",
    "\n",
    "DATASET_DIR_NAME = \"dataset\\set02\\\\02_pair\"\n",
    "ACTUAL_DATASET_NAME = \"pair_test_\" + METHOD\n",
    "ACTUAL_DATASET_PATH = os.path.join(DATASET_DIR_PATH, ACTUAL_DATASET_NAME + \".csv\")\n",
    "\n",
    "RESULT_DIR_NAME = \"dataset\\set02\\\\02_pair\"\n",
    "RESULT_NAME = \"result_\" + \"set02_02_pair_\" + METHOD\n",
    "RESULT_DIR_PATH = os.path.join(os.getcwd(), RESULT_DIR_NAME)\n",
    "RESULT_PATH = os.path.join(RESULT_DIR_PATH, RESULT_NAME + \".csv\")\n",
    "\n",
    "# import unseen data\n",
    "pred_df = pd.read_csv(ACTUAL_DATASET_PATH)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# # check for class validity # #\n",
    "################################\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"Subject\", data=pred_df).set_title(\"Class Validity\")\n",
    "\n",
    "# remove missing values if available\n",
    "pred_df = pred_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = pred_df.values\n",
    "actual_np = pred_dataset[:,CLASSES_COL_NUM]\n",
    "\n",
    "# # divide data into features X\n",
    "# pred_row = pred_dataset[:,3:].astype(float)\n",
    "\n",
    "########################\n",
    "# # predict all rows # #\n",
    "########################\n",
    "pred_row=pred_df.iloc[:,FEATURES_COL_NUM:]\n",
    "\n",
    "#################################\n",
    "# # predict more than one row # #\n",
    "#################################\n",
    "\n",
    "# pred_row=pred_df.iloc[46:54,FEATURES_COL_NUM:]\n",
    "# print(pred_row)\n",
    "\n",
    "############################\n",
    "# # predict a single row # #\n",
    "############################\n",
    "\n",
    "# pred_row=pred_df.iloc[11:12,FEATURES_COL_NUM:]\n",
    "\n",
    "##################\n",
    "# # shape data # #\n",
    "##################\n",
    "pred_row = pred_row.values.tolist()\n",
    "pred_arr = np.asarray(pred_row, dtype=np.float32)\n",
    "pred_arr = np.reshape(pred_arr, (pred_arr.shape[0], TIMESTEPS, pred_arr.shape[1]))\n",
    "\n",
    "print(class_list)\n",
    "Y = np.asarray(class_list)\n",
    "Y = Y.reshape(-1, 1)\n",
    "lb = LabelBinarizer().fit(Y)\n",
    "Y = lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# # get prediction and its label # #\n",
    "####################################\n",
    "\n",
    "pred_proba = model.predict(pred_arr)\n",
    "\n",
    "# pred_proba = np.sum(pred_proba, axis=0)\n",
    "# pred_proba = np.reshape(pred_proba, (1, 9))\n",
    "\n",
    "pred = lb.inverse_transform(pred_proba)\n",
    "acc = np.max(pred_proba, axis=1)\n",
    "\n",
    "match_list = []\n",
    "\n",
    "for _ in range(actual_np.size):\n",
    "    if pred[_] == actual_np[_]:\n",
    "        match_list.append(\"match\")\n",
    "    else:\n",
    "        match_list.append(\"nope\")\n",
    "\n",
    "match_count = match_list.count(\"match\")\n",
    "total_count = len(match_list)\n",
    "\n",
    "match_header = str(match_count) + \"/\" + str(total_count) + \" (\" + str(match_count/total_count*100)+ \"%)\"\n",
    "match_np = np.array(match_list)\n",
    "\n",
    "exported_output = np.column_stack((actual_np, pred))\n",
    "exported_output = np.column_stack((exported_output, acc))\n",
    "exported_output = np.column_stack((exported_output, match_np))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.DataFrame(data=exported_output, index=None, columns=['Actual', 'Prediction', 'Accuracy', match_header])\n",
    "# print(df)\n",
    "df.to_csv(RESULT_PATH)\n",
    "\n",
    "print(\"Accuracy of the Model is: \" + str(match_header))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7d334f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d2798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8af20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3741765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
