{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff04440-8080-4635-ac32-430ac6f7eff4",
   "metadata": {},
   "source": [
    "#### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af71c6bf-604a-4f0c-a18c-6f91bbcf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, \\\n",
    "    BatchNormalization, Flatten, LSTM\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45a7c3",
   "metadata": {},
   "source": [
    "#### PARAMETERS\n",
    "- Set the condition\n",
    "> * N_FEATURES: Number of Features\n",
    "> * CHECK_BLANKS: Check for blank data. If any blank data is found, the whole row of data will be deleted.\n",
    "> * CHECK_CLASS_IMBALANCE: Check for dataset class imbalance. The more balance the dataset, the less biases the model will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7460824",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# # deep learning features # #\n",
    "##############################\n",
    "SEED = 1005 # random seed for reproducibility\n",
    "\n",
    "# should make this dynamic\n",
    "N_FEATURES = 389 #6 #37 #98 #190 #61 #37 #46\n",
    "# N_CLASSES= 9\n",
    "TIMESTEPS = 1\n",
    "EPOCH=200\n",
    "BATCH_SIZE=500\n",
    "\n",
    "###############\n",
    "# # dataset # #\n",
    "###############\n",
    "DATASET_DIR_NAME = \"dataset\"\n",
    "SAMPLE_DATASET_NAME = \"five_train_class\" + \".csv\"\n",
    "ACTUAL_DATASET_NAME = \"five_test_class\" + \".csv\"\n",
    "\n",
    "# SAMPLE_DATASET_NAME = \"train_m2m_tengraph\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"test_m2m_tengraph\" + \".csv\"\n",
    "\n",
    "# SAMPLE_DATASET_NAME = \"andy\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"andy\" + \".csv\"\n",
    "\n",
    "MODEL_DIR_NAME = \"model\"\n",
    "MODEL_NAME = \"classifier\" + \".h5\"\n",
    "\n",
    "DATASET_DIR_PATH = os.path.join(os.getcwd(), DATASET_DIR_NAME)\n",
    "SAMPLE_DATASET_PATH = os.path.join(DATASET_DIR_PATH, SAMPLE_DATASET_NAME)\n",
    "ACTUAL_DATASET_PATH = os.path.join(DATASET_DIR_PATH, ACTUAL_DATASET_NAME)\n",
    "\n",
    "MODEL_DIR_PATH = os.path.join(os.getcwd(), MODEL_DIR_NAME)\n",
    "MODEL_PATH = os.path.join(MODEL_DIR_PATH, MODEL_NAME)\n",
    "\n",
    "CLASSES_COL_NAME = \"Subject\"\n",
    "CLASSES_COL_NUM = 0\n",
    "FEATURES_COL_NUM = 3 #4\n",
    "CLASS_LIST = ['adhy', 'alan', 'andy', 'bryce', 'chris', 'cy', 'gerald', 'jc', 'jonah', 'qk']\n",
    "# CLASS_LIST = ['andy', 'azfar', 'gerald', 'jonah', 'ys']\n",
    "\n",
    "#################\n",
    "# # sns theme # #\n",
    "#################\n",
    "# sns.set_theme(style=\"darkgrid\") # (dark background with white gridlines)\n",
    "sns.set_theme(style=\"whitegrid\") # (white background with grey gridlines)\n",
    "# sns.set_theme(style=\"dark\") # (dark background with no gridlines)\n",
    "# sns.set_theme(style=\"white\") # (white background with no gridlines)\n",
    "# sns.set_theme(style=\"ticks\") # (white background with axis ticks and no gridlines)\n",
    "\n",
    "def df_drop(df):\n",
    "    # df.drop(df[df['Subject']=='andy'].index, inplace=True)\n",
    "    # df.drop(df[df['Subject']=='azfar'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='ch'].index, inplace=True)\n",
    "    # df.drop(df[df['Subject']=='cy'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='gerald'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='jc'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='jonah'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='qikai'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='ys'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='zen'].index, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971b4aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory exists at: C:\\Users\\spencer\\Documents\\Github\\deep-captcha\\dataset\n",
      "Model directory exists at: C:\\Users\\spencer\\Documents\\Github\\deep-captcha\\model\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(DATASET_DIR_PATH) is True:\n",
    "    print(f\"Dataset directory exists at: {DATASET_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(DATASET_DIR_PATH, 666)\n",
    "        print(f\"Dataset directory have been created at: {DATASET_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Dataset Directory not created\")\n",
    "        \n",
    "if os.path.isdir(MODEL_DIR_PATH) is True:\n",
    "    print(f\"Model directory exists at: {MODEL_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(MODEL_DIR_PATH, 666)\n",
    "        print(f\"Model directory have been created at: {MODEL_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Model Directory not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52cdd5",
   "metadata": {},
   "source": [
    "#### CREATE MODEL\n",
    "- Create base model\n",
    "- Wrap it with KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f633b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base model\n",
    "def create_base_model():\n",
    "    model = Sequential()\n",
    "#     model.add(LSTM(units=128, return_sequences=True, \n",
    "#                  input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=1024, return_sequences=True,\n",
    "             input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=512, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=256, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=32, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    # softmax for multi-class classification\n",
    "    model.add(Flatten())\n",
    "    print(n_classes)\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# wrap model in KerasClassifier\n",
    "def create_model():\n",
    "    model = KerasClassifier(build_fn=create_base_model, epochs=EPOCH, \n",
    "                            batch_size=BATCH_SIZE)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2280ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # divide data into features X and target (classes) Y\n",
    "def prepare_dataset(df):\n",
    "    X = df.values[:,6:].astype(float)\n",
    "    Xw = df.values[:,3:4].astype(float)\n",
    "    Xy = df.values[:,4:5].astype(float)\n",
    "    Xz = df.values[:,5:6].astype(float)\n",
    "#     print(Xw)\n",
    "#     print(Xy)\n",
    "#     print(Xz)\n",
    "    Y = df.values[:,CLASSES_COL_NUM].astype(str)\n",
    "\n",
    "    # convert target Y to labelbinarizer Y for model\n",
    "    # fit_transform is not used to reuse lb\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    lb = LabelBinarizer().fit(Y)\n",
    "    Y = lb.transform(Y)\n",
    "    Yw = LabelBinarizer().fit(Xw)\n",
    "    \n",
    "#     print(Xw.shape)\n",
    "#     print(Xw)\n",
    "    Xw = Yw.transform(Xw)\n",
    "    \n",
    "#     print(Xw)\n",
    "#     print(Xw.shape)\n",
    "    Yx = LabelBinarizer().fit(Xy)\n",
    "    Xy = Yx.transform(Xy)\n",
    "    \n",
    "    print(Xz)\n",
    "    print(Xz.shape)\n",
    "    Yz = LabelBinarizer().fit(Xz)\n",
    "    Xz = Yz.transform(Xz)\n",
    "    print(Xz)\n",
    "    print(Xz.shape)\n",
    "    print(\"hello\")\n",
    "    Xz = np.reshape(Xz, (9360, 1))\n",
    "    \n",
    "    print(Xz)\n",
    "    print(Xz.shape)\n",
    "                     \n",
    "    xx = np.concatenate((Xw, Xy), axis=1)\n",
    "    print(xx.shape)\n",
    "    xx = np.concatenate((xx, Xz), axis=1)\n",
    "    xx = np.concatenate((xx, X), axis=1)\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # # get all the encoded class # #\n",
    "    #################################\n",
    "    print(\"LabelBinarizer is able to decipher: \")\n",
    "#     print(lb.classes_)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ###########################\n",
    "    # # print X and Y shape # #\n",
    "    ###########################\n",
    "    print(f\"X | Features | Dataset Shape: {xx.shape}\")\n",
    "    print(f\"Y | Classes  | Dataset Shape: {Y.shape}\")\n",
    "\n",
    "    return xx, Y, lb, Yw, Yx, Yz\n",
    "\n",
    "# divide data into features X and target (classes) Y\n",
    "# def prepare_dataset(df):\n",
    "#     df = pd.get_dummies(df, columns=[\"Char_Init\"])\n",
    "#     df = pd.get_dummies(df, columns=[\"Char_End\"])\n",
    "#     df = pd.get_dummies(df, columns=[\"Char_Total_Int\"])\n",
    "\n",
    "#     X = df.values[:,FEATURES_COL_NUM:].astype(float)\n",
    "#     Y = df.values[:,CLASSES_COL_NUM].astype(str)\n",
    "\n",
    "#     # convert target Y to labelbinarizer Y for model\n",
    "#     # fit_transform is not used to reuse lb\n",
    "#     Y = Y.reshape(-1, 1)\n",
    "#     lb = LabelBinarizer().fit(Y)\n",
    "#     Y = lb.transform(Y)\n",
    "\n",
    "\n",
    "#     #################################\n",
    "#     # # get all the encoded class # #\n",
    "#     #################################\n",
    "#     print(\"LabelBinarizer is able to decipher: \")\n",
    "# #     print(lb.classes_)\n",
    "#     print(\"\\n\")\n",
    "\n",
    "#     ###########################\n",
    "#     # # print X and Y shape # #\n",
    "#     ###########################\n",
    "#     print(f\"X | Features | Dataset Shape: {X.shape}\")\n",
    "#     print(f\"Y | Classes  | Dataset Shape: {Y.shape}\")\n",
    "\n",
    "#     return X, Y, lb\n",
    "\n",
    "\n",
    "\n",
    "# X, Y, lb, Yw, Yx, Yz = prepare_dataset(df)\n",
    "# X, Y, lb, Yw, Yx, Yz = prepare_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a2b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_shape_dataset(X, Y, SPLIT_RATIO, TIMESTEPS, SEED):\n",
    "\n",
    "    ##############################################################\n",
    "    # # split dataset into train and test set of 0.8/0.2 ratio # #\n",
    "    ##############################################################\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=SPLIT_RATIO, random_state=SEED)\n",
    "\n",
    "    ############################\n",
    "    # # reshaping of dataset # #\n",
    "    ############################\n",
    "\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], TIMESTEPS, X_train.shape[1]))\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], TIMESTEPS, X_test.shape[1]))\n",
    "\n",
    "    # retrieve number of classes\n",
    "    n_classes = y_train.shape[1]\n",
    "\n",
    "    print(f\"X train shape: {X_train.shape}\")\n",
    "    print(f\"Y train shape: {y_train.shape}\")\n",
    "    print(f\"X test shape: {X_test.shape}\")\n",
    "    print(f\"Y test shape: {y_test.shape}\")\n",
    "    print(f\"Number of Classes: {n_classes}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, n_classes\n",
    "\n",
    "def reshape_dataset(X, TIMESTEPS):\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    X = np.reshape(X, (X.shape[0], TIMESTEPS, X.shape[1]))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13daa1c",
   "metadata": {},
   "source": [
    "#### CHECK DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7d2ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     sns.catplot(x=\"Subject\", y=\"D|0\", data=df)\n",
    "\n",
    "    \n",
    "#     sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|3\", hue=\"D|3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|4\", hue=\"D|4\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|5\", hue=\"D|5\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|6\", hue=\"D|6\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|7\", hue=\"D|7\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|8\", hue=\"D|8\", data=df, legend=False)\n",
    "\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"I|1+2\", hue=\"I|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"PF|1+2\", hue=\"PF|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"RF|1+2\", hue=\"RF|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"DT|1+2\", hue=\"DT|1+2\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|9\", hue=\"D|9\", data=df, legend=False)\n",
    "\n",
    "\n",
    "#     sns.catplot(x=\"Subject\", y=\"TT|1+3\", hue=\"TT|1+3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"QT|1+4\", hue=\"QT|1+4\", data=df, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b17bde",
   "metadata": {},
   "source": [
    "#### FIT AND SAVE MODEL\n",
    "- Fitting of model\n",
    "- Get Accuracy and Loss of Mdoel\n",
    "- Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5703966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[158.]\n",
      " [813.]\n",
      " [130.]\n",
      " ...\n",
      " [  4.]\n",
      " [ 45.]\n",
      " [523.]]\n",
      "(9360, 1)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(9360, 307)\n",
      "hello\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2873520 into shape (9360,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20472/2135542448.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# divide data into features X and target (classes) Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# convert target Y to labelbinarizer Y for model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# reshaping the dataset to include LSTM Timesteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20472/1452395085.py\u001b[0m in \u001b[0;36mprepare_dataset\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hello\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mXz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m9360\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    296\u001b[0m            [5, 6]])\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2873520 into shape (9360,1)"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# # reshaping of dataset # #\n",
    "############################\n",
    "# loading of dataset\n",
    "df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "df.head()\n",
    "\n",
    "# df = df_drop(df)\n",
    "dataset = df.values\n",
    "\n",
    "# divide data into features X and target (classes) Y\n",
    "# convert target Y to labelbinarizer Y for model\n",
    "X, Y, lb, Yw, Yx, Yz = prepare_dataset(df)\n",
    "\n",
    "# reshaping the dataset to include LSTM Timesteps\n",
    "X = reshape_dataset(X, TIMESTEPS)\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "#####################\n",
    "# # fit the model # #\n",
    "#####################\n",
    "\n",
    "model = create_model()\n",
    "es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
    "                   verbose=0)\n",
    "history = model.fit(X, Y, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1771e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# # get model accuracy # #\n",
    "##########################\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "######################\n",
    "# # get model loss # #\n",
    "######################\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d2413",
   "metadata": {},
   "source": [
    "#### SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # save model # #\n",
    "##################\n",
    "model.model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799eac",
   "metadata": {},
   "source": [
    "# LIVE TESTING\n",
    "> Live test with new dataset to check if model function as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0074460",
   "metadata": {},
   "source": [
    "#### LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da540d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # load model # #\n",
    "##################\n",
    "\n",
    "# model = create_model()\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f0646",
   "metadata": {},
   "source": [
    "#### LOAD DATA\n",
    "- Import new dataset to verify the model is able to predict accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bff51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unseen data\n",
    "pred_df = pd.read_csv(ACTUAL_DATASET_PATH)\n",
    "pred_df.head()\n",
    "\n",
    "print(pred_df.shape)\n",
    "# pred_df = df_drop(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# # check for class validity # #\n",
    "################################\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"Subject\", data=pred_df).set_title(\"Class Validity\")\n",
    "\n",
    "# remove missing values if available\n",
    "pred_df = pred_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b061d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = pred_df.values\n",
    "results = pred_dataset[:,CLASSES_COL_NUM]\n",
    "\n",
    "# # divide data into features X\n",
    "# pred_row = pred_dataset[:,3:].astype(float)\n",
    "\n",
    "########################\n",
    "# # predict all rows # #\n",
    "########################\n",
    "pred_row=pred_df.iloc[:,FEATURES_COL_NUM:]\n",
    "\n",
    "X = pred_df.values[:,6:].astype(float)\n",
    "Xw = pred_df.values[:,3:4].astype(float)\n",
    "Xy = pred_df.values[:,4:5].astype(float)\n",
    "Xz = pred_df.values[:,5:6].astype(float)\n",
    "\n",
    "#################################\n",
    "# # predict more than one row # #\n",
    "#################################\n",
    "\n",
    "# pred_row=pred_df.iloc[46:54,FEATURES_COL_NUM:]\n",
    "# print(pred_row)\n",
    "\n",
    "############################\n",
    "# # predict a single row # #\n",
    "############################\n",
    "\n",
    "# pred_row=pred_df.iloc[11:12,FEATURES_COL_NUM:]\n",
    "\n",
    "##################\n",
    "# # shape data # #\n",
    "##################\n",
    "pred_row = pred_row.values.tolist()\n",
    "pred_arr = np.asarray(pred_row, dtype=np.float32)\n",
    "pred_arr = np.reshape(pred_arr, (pred_arr.shape[0], TIMESTEPS, pred_arr.shape[1]))\n",
    "\n",
    "Y = CLASS_LIST\n",
    "print(Y)\n",
    "Y = np.asarray(Y)\n",
    "Y = Y.reshape(-1, 1)\n",
    "lb = LabelBinarizer().fit(Y)\n",
    "Y = lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad543869",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# # get prediction and its label # #\n",
    "####################################\n",
    "\n",
    "pred_proba = model.predict(pred_arr)\n",
    "\n",
    "# pred_proba = np.sum(pred_proba, axis=0)\n",
    "# pred_proba = np.reshape(pred_proba, (1, 10))\n",
    "\n",
    "pred = lb.inverse_transform(pred_proba)\n",
    "acc = np.max(pred_proba, axis=1)\n",
    "\n",
    "pred_results = np.column_stack((pred, acc))\n",
    "# pred_results = np.column_stack((results, pred_results))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# df = pd.DataFrame(data=pred_results, index=None, columns=['Results', 'Prediction', 'Accuracy'])\n",
    "df = pd.DataFrame(data=pred_results, index=None, columns=['Prediction', 'Accuracy'])\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7d334f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d2798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8af20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3741765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
