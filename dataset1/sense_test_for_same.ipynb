{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff04440-8080-4635-ac32-430ac6f7eff4",
   "metadata": {},
   "source": [
    "#### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af71c6bf-604a-4f0c-a18c-6f91bbcf9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, \\\n",
    "    BatchNormalization, Flatten, LSTM\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45a7c3",
   "metadata": {},
   "source": [
    "#### PARAMETERS\n",
    "- Set the condition\n",
    "> * N_FEATURES: Number of Features\n",
    "> * CHECK_BLANKS: Check for blank data. If any blank data is found, the whole row of data will be deleted.\n",
    "> * CHECK_CLASS_IMBALANCE: Check for dataset class imbalance. The more balance the dataset, the less biases the model will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7460824",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# # deep learning features # #\n",
    "##############################\n",
    "SEED = 1005 # random seed for reproducibility\n",
    "\n",
    "# should make this dynamic\n",
    "N_FEATURES = 220 #36 #220 #9 #220 #36 #36 #120 #220\n",
    "# N_CLASSES= 12\n",
    "TIMESTEPS = 1\n",
    "EPOCH=300\n",
    "BATCH_SIZE=10\n",
    "\n",
    "###############\n",
    "# # dataset # #\n",
    "###############\n",
    "DATASET_DIR_NAME = \"dataset\\set04\\\\11_same\"\n",
    "# SAMPLE_DATASET_NAME = \"own_train_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"own_test_full\" + \".csv\"\n",
    "\n",
    "# ACTUAL_DATASET_NAME = \"combi_andy_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_azfar_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_bryce_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_chris_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_cy_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_gerald_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_ken_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_sz_full\" + \".csv\" #notdone\n",
    "# ACTUAL_DATASET_NAME = \"combi_vale_full\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"combi_ye_full\" + \".csv\"  #notdone\n",
    "# ACTUAL_DATASET_NAME = \"combi_ys_full\" + \".csv\" #notdone\n",
    "\n",
    "# SAMPLE_DATASET_NAME = \"own_train_semi\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"own_test_semi\" + \".csv\"\n",
    "# SAMPLE_DATASET_NAME = \"own_train_bare\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"own_test_bare\" + \".csv\"\n",
    "# SAMPLE_DATASET_NAME = \"own_train_5\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"own_test_5\" + \".csv\"\n",
    "SAMPLE_DATASET_NAME = \"same_train\" + \".csv\"\n",
    "ACTUAL_DATASET_NAME = \"same_test\" + \".csv\"\n",
    "# SAMPLE_DATASET_NAME = \"same_train_semi\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"same_test_semi\" + \".csv\"\n",
    "# SAMPLE_DATASET_NAME = \"same_train_bare\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"same_test_bare\" + \".csv\"\n",
    "# SAMPLE_DATASET_NAME = \"same_train_5\" + \".csv\"\n",
    "# ACTUAL_DATASET_NAME = \"same_test_5\" + \".csv\"\n",
    "\n",
    "\n",
    "MODEL_DIR_NAME = \"model\"\n",
    "MODEL_NAME = \"same_full_model_del\" + \".h5\"\n",
    "RESULT_NAME = \"same_full_del\" + \".csv\"\n",
    "\n",
    "# MODEL_DIR_NAME = \"dataset\\set04\\\\11_same\"\n",
    "# MODEL_NAME = \"model_\" + \"set04_11_same.h5\"\n",
    "# RESULT_NAME = \"same_full_del_1\" + \".csv\"\n",
    "\n",
    "DATASET_DIR_PATH = os.path.join(os.getcwd(), DATASET_DIR_NAME)\n",
    "SAMPLE_DATASET_PATH = os.path.join(DATASET_DIR_PATH, SAMPLE_DATASET_NAME)\n",
    "ACTUAL_DATASET_PATH = os.path.join(DATASET_DIR_PATH, ACTUAL_DATASET_NAME)\n",
    "\n",
    "MODEL_DIR_PATH = os.path.join(os.getcwd(), MODEL_DIR_NAME)\n",
    "MODEL_PATH = os.path.join(MODEL_DIR_PATH, MODEL_NAME)\n",
    "\n",
    "CLASSES_COL_NAME = \"Subject\"\n",
    "CLASSES_COL_NUM = 0\n",
    "FEATURES_COL_NUM = 2\n",
    "\n",
    "CLASS_LIST = ['andy', 'azfar', 'bryce', 'chris', 'cy', 'gerald', 'ken', 'qk', 'sz', 'vale', 'ye', 'ys']\n",
    "\n",
    "#################\n",
    "# # sns theme # #\n",
    "#################\n",
    "# sns.set_theme(style=\"darkgrid\") # (dark background with white gridlines)\n",
    "sns.set_theme(style=\"whitegrid\") # (white background with grey gridlines)\n",
    "# sns.set_theme(style=\"dark\") # (dark background with no gridlines)\n",
    "# sns.set_theme(style=\"white\") # (white background with no gridlines)\n",
    "# sns.set_theme(style=\"ticks\") # (white background with axis ticks and no gridlines)\n",
    "\n",
    "def df_drop(df):\n",
    "#     df.drop(df[df['Subject']=='adhy'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='alan'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='andy'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='bryce'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='chris'].index, inplace=True)\n",
    "#     df.drop(df[df['Subject']=='cy'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='gerald'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='jc'].index, inplace=True)\n",
    "    df.drop(df[df['Subject']=='jonah'].index, inplace=True)\n",
    "#     df.drop(df[df['Subject']=='qk'].index, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971b4aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory exists at: C:\\Users\\andyc\\Documents\\GitHub\\ict4001-cap\\dataset\\set04\\11_same\n",
      "Model directory exists at: C:\\Users\\andyc\\Documents\\GitHub\\ict4001-cap\\model\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(DATASET_DIR_PATH) is True:\n",
    "    print(f\"Dataset directory exists at: {DATASET_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(DATASET_DIR_PATH, 666)\n",
    "        print(f\"Dataset directory have been created at: {DATASET_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Dataset Directory not created\")\n",
    "        \n",
    "if os.path.isdir(MODEL_DIR_PATH) is True:\n",
    "    print(f\"Model directory exists at: {MODEL_DIR_PATH}\")\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir(MODEL_DIR_PATH, 666)\n",
    "        print(f\"Model directory have been created at: {MODEL_DIR_PATH}\")\n",
    "    except:\n",
    "        print(\"Error: Model Directory not created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52cdd5",
   "metadata": {},
   "source": [
    "#### CREATE MODEL\n",
    "- Create base model\n",
    "- Wrap it with KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f633b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base model\n",
    "def create_base_model():\n",
    "    model = Sequential()\n",
    "#     model.add(LSTM(units=1024, return_sequences=True,\n",
    "#              input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "#     model.add(Dense(1024, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.2))\n",
    "# #     model.add(BatchNormalization())\n",
    "    \n",
    "#     model.add(LSTM(units=512, return_sequences=True))\n",
    "#     model.add(Dense(512, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.2))\n",
    "# #     model.add(BatchNormalization())\n",
    "    \n",
    "#     model.add(LSTM(units=256, return_sequences=True))\n",
    "#     model.add(Dense(256, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units=128, return_sequences=True,\n",
    "             input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "    model.add(Dense(128, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dense(64, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(LSTM(units=32, return_sequences=True))\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(BatchNormalization())\n",
    "    \n",
    "#     model.add(LSTM(units=128, return_sequences=True))\n",
    "#     model.add(Activation=\"sigmoid\")\n",
    "#     model.add(Dropout(0.2))\n",
    "# #     model.add(BatchNormalization())\n",
    "    \n",
    "#     model.add(LSTM(units=64, return_sequences=True))\n",
    "#     model.add(Activation=\"sigmoid\")\n",
    "#     model.add(Dropout(0.2))\n",
    "# #     model.add(BatchNormalization())\n",
    "    \n",
    "#     model.add(LSTM(units=32, return_sequences=True))\n",
    "#     model.add(Activation=\"sigmoid\")\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "    # softmax for multi-class classification\n",
    "    model.add(Flatten())\n",
    "    print(n_classes)\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "\n",
    "    # model.add(LSTM(units=128, return_sequences=True, \n",
    "    #              input_shape=(TIMESTEPS,N_FEATURES)))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(LSTM(units=128, return_sequences=True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(LSTM(units=64, return_sequences=True))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(BatchNormalization())\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "# wrap model in KerasClassifier\n",
    "def create_model():\n",
    "    model = KerasClassifier(build_fn=create_base_model, epochs=EPOCH, \n",
    "                            batch_size=BATCH_SIZE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2280ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into features X and target (classes) Y\n",
    "def prepare_dataset(df):\n",
    "    X = df.values[:,FEATURES_COL_NUM:].astype(float)\n",
    "    Y = df.values[:,CLASSES_COL_NUM].astype(str)\n",
    "\n",
    "    # convert target Y to labelbinarizer Y for model\n",
    "    # fit_transform is not used to reuse lb\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    lb = LabelBinarizer().fit(Y)\n",
    "    Y = lb.transform(Y)\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # # get all the encoded class # #\n",
    "    #################################\n",
    "    print(\"LabelBinarizer is able to decipher: \")\n",
    "    print(lb.classes_)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ###########################\n",
    "    # # print X and Y shape # #\n",
    "    ###########################\n",
    "    print(f\"X | Features | Dataset Shape: {X.shape}\")\n",
    "    print(f\"Y | Classes  | Dataset Shape: {Y.shape}\")\n",
    "\n",
    "    return X, Y, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2cd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_shape_dataset(X, Y, SPLIT_RATIO, TIMESTEPS, SEED):\n",
    "\n",
    "    ##############################################################\n",
    "    # # split dataset into train and test set of 0.8/0.2 ratio # #\n",
    "    ##############################################################\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, Y, test_size=SPLIT_RATIO, random_state=SEED)\n",
    "\n",
    "    ############################\n",
    "    # # reshaping of dataset # #\n",
    "    ############################\n",
    "\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    print(X_train.dtype)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], TIMESTEPS, X_train.shape[1]))\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    print(X_test.dtype)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], TIMESTEPS, X_test.shape[1]))\n",
    "\n",
    "    # retrieve number of classes\n",
    "    n_classes = y_train.shape[1]\n",
    "\n",
    "    print(f\"X train shape: {X_train.shape}\")\n",
    "    print(f\"Y train shape: {y_train.shape}\")\n",
    "    print(f\"X test shape: {X_test.shape}\")\n",
    "    print(f\"Y test shape: {y_test.shape}\")\n",
    "    print(f\"Number of Classes: {n_classes}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, n_classes\n",
    "\n",
    "def reshape_dataset(X, TIMESTEPS):\n",
    "    # reshaping the dataset to include LSTM Timesteps\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    X = np.reshape(X, (X.shape[0], TIMESTEPS, X.shape[1]))\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13daa1c",
   "metadata": {},
   "source": [
    "#### CHECK DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d2ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     sns.catplot(x=\"Subject\", y=\"D|0\", data=df)\n",
    "\n",
    "    \n",
    "#     sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|3\", hue=\"D|3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|4\", hue=\"D|4\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|5\", hue=\"D|5\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|6\", hue=\"D|6\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|7\", hue=\"D|7\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"D|8\", hue=\"D|8\", data=df, legend=False)\n",
    "# df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "# df.head()\n",
    "# sns.catplot(x=\"Subject\", y=\"D|1\", hue=\"D|1\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"I|1+2\", hue=\"I|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"PF|1+2\", hue=\"PF|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"RF|1+2\", hue=\"RF|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"DT|1+2\", hue=\"DT|1+2\", data=df, legend=False)\n",
    "# sns.catplot(x=\"Subject\", y=\"D|9\", hue=\"D|9\", data=df, legend=False)\n",
    "\n",
    "\n",
    "#     sns.catplot(x=\"Subject\", y=\"TT|1+3\", hue=\"TT|1+3\", data=df, legend=False)\n",
    "#     sns.catplot(x=\"Subject\", y=\"QT|1+4\", hue=\"QT|1+4\", data=df, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b17bde",
   "metadata": {},
   "source": [
    "#### FIT AND SAVE MODEL\n",
    "- Fitting of model\n",
    "- Get Accuracy and Loss of Mdoel\n",
    "- Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5703966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelBinarizer is able to decipher: \n",
      "['andy' 'azfar' 'bryce' 'chris' 'cy' 'gerald' 'ken' 'qk' 'sz' 'vale' 'ye'\n",
      " 'ys']\n",
      "\n",
      "\n",
      "X | Features | Dataset Shape: (1200, 220)\n",
      "Y | Classes  | Dataset Shape: (1200, 12)\n",
      "12\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 4s 5ms/step - loss: 2.5414 - accuracy: 0.0783\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 2.4792 - accuracy: 0.1117\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 2.3352 - accuracy: 0.1350\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 2.1974 - accuracy: 0.1800\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 2.1359 - accuracy: 0.2025\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 2.0666 - accuracy: 0.1917\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.9958 - accuracy: 0.2175\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.9218 - accuracy: 0.2342\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.9574 - accuracy: 0.2158\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.8929 - accuracy: 0.2250\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.8608 - accuracy: 0.2458\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.8477 - accuracy: 0.2408\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.8385 - accuracy: 0.2392\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.7727 - accuracy: 0.2633\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.7836 - accuracy: 0.2550\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.7727 - accuracy: 0.2467\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.7451 - accuracy: 0.2625\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.7216 - accuracy: 0.3042\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.6853 - accuracy: 0.3050\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.6989 - accuracy: 0.2967\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.6905 - accuracy: 0.2975\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.6283 - accuracy: 0.3258\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.6008 - accuracy: 0.3058\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.6362 - accuracy: 0.3150\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.6474 - accuracy: 0.3067\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5876 - accuracy: 0.3367\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.5740 - accuracy: 0.3100\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.5747 - accuracy: 0.3267\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5833 - accuracy: 0.3158\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5606 - accuracy: 0.3133\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5543 - accuracy: 0.3342\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.5327 - accuracy: 0.3317\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5798 - accuracy: 0.3192\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.5444 - accuracy: 0.3292\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5353 - accuracy: 0.3233\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5226 - accuracy: 0.3375\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.5285 - accuracy: 0.3292\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.4996 - accuracy: 0.3583\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4915 - accuracy: 0.3483\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4905 - accuracy: 0.3383\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.5259 - accuracy: 0.3283\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.5500 - accuracy: 0.3250\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.5076 - accuracy: 0.3400\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.5045 - accuracy: 0.3400\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4446 - accuracy: 0.3633\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4703 - accuracy: 0.3467\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4550 - accuracy: 0.3533\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4444 - accuracy: 0.3725\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.4928 - accuracy: 0.3392\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4469 - accuracy: 0.3425\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.4707 - accuracy: 0.3525\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.4357 - accuracy: 0.3758\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4181 - accuracy: 0.3592\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4284 - accuracy: 0.3792\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4269 - accuracy: 0.3792\n",
      "Epoch 56/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4174 - accuracy: 0.3967\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.4130 - accuracy: 0.3817\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4425 - accuracy: 0.3633\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4399 - accuracy: 0.3933\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4060 - accuracy: 0.3825\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3835 - accuracy: 0.4067\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3958 - accuracy: 0.3992\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4335 - accuracy: 0.3867\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.4004 - accuracy: 0.3975\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3482 - accuracy: 0.4300\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3291 - accuracy: 0.4408\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3555 - accuracy: 0.4167\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3325 - accuracy: 0.4275\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3210 - accuracy: 0.4567\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3239 - accuracy: 0.4517\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.3027 - accuracy: 0.4558\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2947 - accuracy: 0.4892\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2593 - accuracy: 0.4842\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2837 - accuracy: 0.4633\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2734 - accuracy: 0.5017\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2629 - accuracy: 0.5133\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2355 - accuracy: 0.4875\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2106 - accuracy: 0.5033\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1827 - accuracy: 0.5225\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.2416 - accuracy: 0.5183\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1818 - accuracy: 0.5333\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1529 - accuracy: 0.5442\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1599 - accuracy: 0.5267\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1238 - accuracy: 0.5542\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1051 - accuracy: 0.5558\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1137 - accuracy: 0.5625\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.1151 - accuracy: 0.5767\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0900 - accuracy: 0.5583\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0677 - accuracy: 0.5608\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0394 - accuracy: 0.5767\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0944 - accuracy: 0.5733\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0819 - accuracy: 0.5742\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0434 - accuracy: 0.5792\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0647 - accuracy: 0.5658\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0136 - accuracy: 0.5950\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 1.0609 - accuracy: 0.5900\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0215 - accuracy: 0.6033\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0613 - accuracy: 0.5942\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0029 - accuracy: 0.6033\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 1.0471 - accuracy: 0.5875\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9446 - accuracy: 0.6350\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.9736 - accuracy: 0.6183\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9648 - accuracy: 0.6250\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.9718 - accuracy: 0.6383\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1.0113 - accuracy: 0.5933\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9572 - accuracy: 0.6225\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9246 - accuracy: 0.6358\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9508 - accuracy: 0.6267\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9049 - accuracy: 0.6608\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8996 - accuracy: 0.6483\n",
      "Epoch 111/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9767 - accuracy: 0.6250\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9465 - accuracy: 0.6383\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.9426 - accuracy: 0.6467\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9047 - accuracy: 0.6808\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8830 - accuracy: 0.6933\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8873 - accuracy: 0.6958\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8383 - accuracy: 0.7217\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.9096 - accuracy: 0.6767\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8831 - accuracy: 0.6967\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8158 - accuracy: 0.7167\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8622 - accuracy: 0.7092\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8374 - accuracy: 0.7142\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8268 - accuracy: 0.7233\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8657 - accuracy: 0.7217\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7672 - accuracy: 0.7408\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.8126 - accuracy: 0.7317\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7509 - accuracy: 0.7483\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7910 - accuracy: 0.7183\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7433 - accuracy: 0.7542\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.7238 - accuracy: 0.7575\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.7868 - accuracy: 0.7333\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7039 - accuracy: 0.7558\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7381 - accuracy: 0.7525\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7659 - accuracy: 0.7467\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7126 - accuracy: 0.7608\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.8417 - accuracy: 0.7117\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7503 - accuracy: 0.7492\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6969 - accuracy: 0.7583\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6961 - accuracy: 0.7717\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6942 - accuracy: 0.7683\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6917 - accuracy: 0.7650\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6809 - accuracy: 0.7858\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6412 - accuracy: 0.7883\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6560 - accuracy: 0.7808\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6943 - accuracy: 0.7725\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6525 - accuracy: 0.7808\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6591 - accuracy: 0.7683\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.7917\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6484 - accuracy: 0.7800\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6455 - accuracy: 0.7858\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6991 - accuracy: 0.7625\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.7137 - accuracy: 0.7542\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6128 - accuracy: 0.7858\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6709 - accuracy: 0.7792\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6347 - accuracy: 0.7850\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6060 - accuracy: 0.7942\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6442 - accuracy: 0.7808\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5468 - accuracy: 0.8117\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6470 - accuracy: 0.7758\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6230 - accuracy: 0.7950\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5448 - accuracy: 0.8208\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6082 - accuracy: 0.7875\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.7883\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5632 - accuracy: 0.8025\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5772 - accuracy: 0.8100\n",
      "Epoch 166/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.8250\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7183 - accuracy: 0.7608\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.7670 - accuracy: 0.7483\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6093 - accuracy: 0.8025\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5451 - accuracy: 0.8217\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5496 - accuracy: 0.8158\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5831 - accuracy: 0.7925\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.8242\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.8192\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5637 - accuracy: 0.8033\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5605 - accuracy: 0.8250\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5777 - accuracy: 0.7983\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.8142\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5765 - accuracy: 0.8250\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6387 - accuracy: 0.7817\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5877 - accuracy: 0.8000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.8258\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.8158\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.8308\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5962 - accuracy: 0.8075\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4820 - accuracy: 0.8358\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.8242\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.8300\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.8383\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.8250\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5254 - accuracy: 0.8267\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5459 - accuracy: 0.8117\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5532 - accuracy: 0.8017\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.8467\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4852 - accuracy: 0.8225\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6052 - accuracy: 0.8000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4995 - accuracy: 0.8333\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4729 - accuracy: 0.8342\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.6636 - accuracy: 0.7783\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5047 - accuracy: 0.8217\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.8558\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.8450\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5506 - accuracy: 0.8217\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.8517\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.8242\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4629 - accuracy: 0.8425\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4653 - accuracy: 0.8458\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4690 - accuracy: 0.8450\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5130 - accuracy: 0.8308\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5166 - accuracy: 0.8350\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4429 - accuracy: 0.8492\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.6060 - accuracy: 0.7833\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4971 - accuracy: 0.8367\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.8467\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8650\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8683\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4490 - accuracy: 0.8525\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4293 - accuracy: 0.8533\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4280 - accuracy: 0.8483\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4851 - accuracy: 0.8483\n",
      "Epoch 221/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4234 - accuracy: 0.8550\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8592\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8650\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4253 - accuracy: 0.8533\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.8117\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4535 - accuracy: 0.8475\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8583\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3988 - accuracy: 0.8658\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3844 - accuracy: 0.8683\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.8350\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.8383\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.8517\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.8592\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8608\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.8242\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.8575\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8717\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8550\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4143 - accuracy: 0.8642\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4211 - accuracy: 0.8650\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4773 - accuracy: 0.8383\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3711 - accuracy: 0.8717\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4077 - accuracy: 0.8550\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3844 - accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8575\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4010 - accuracy: 0.8692\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4361 - accuracy: 0.8467\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4466 - accuracy: 0.8458\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4609 - accuracy: 0.8325\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4325 - accuracy: 0.8500\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3872 - accuracy: 0.8675\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3810 - accuracy: 0.8725\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3796 - accuracy: 0.8675\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4143 - accuracy: 0.8675\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4035 - accuracy: 0.8608\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3838 - accuracy: 0.8633\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3557 - accuracy: 0.8800\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3994 - accuracy: 0.8592\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8633\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3966 - accuracy: 0.8600\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3757 - accuracy: 0.8717\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3458 - accuracy: 0.8908\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3948 - accuracy: 0.8725\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4399 - accuracy: 0.8467\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3894 - accuracy: 0.8767\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3534 - accuracy: 0.8783\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3861 - accuracy: 0.8733\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3346 - accuracy: 0.8900\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4548 - accuracy: 0.8433\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3886 - accuracy: 0.8742\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3700 - accuracy: 0.8808\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3649 - accuracy: 0.8750\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8683\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.8783\n",
      "Epoch 276/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.8808\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3458 - accuracy: 0.8767\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8650\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.8900\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4422 - accuracy: 0.8525\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.5342 - accuracy: 0.8283\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3747 - accuracy: 0.8592\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3785 - accuracy: 0.8725\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3214 - accuracy: 0.8933\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3201 - accuracy: 0.8850\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8800\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3586 - accuracy: 0.8742\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.4334 - accuracy: 0.8542\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3284 - accuracy: 0.8983\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 1s 4ms/step - loss: 0.3396 - accuracy: 0.8850\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8533\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3701 - accuracy: 0.8742\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8783\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3013 - accuracy: 0.8917\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.8408\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3732 - accuracy: 0.8675\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3731 - accuracy: 0.8675\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.8942\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.8617\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.3059 - accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# # reshaping of dataset # #\n",
    "############################\n",
    "# loading of dataset\n",
    "df = pd.read_csv(SAMPLE_DATASET_PATH)\n",
    "df.head()\n",
    "\n",
    "# df = df_drop(df)\n",
    "dataset = df.values\n",
    "\n",
    "# divide data into features X and target (classes) Y\n",
    "# convert target Y to labelbinarizer Y for model\n",
    "X, Y, lb = prepare_dataset(df)\n",
    "\n",
    "# reshaping the dataset to include LSTM Timesteps\n",
    "X = reshape_dataset(X, TIMESTEPS)\n",
    "n_classes = Y.shape[1]\n",
    "\n",
    "#####################\n",
    "# # fit the model # #\n",
    "#####################\n",
    "\n",
    "model = create_model()\n",
    "es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, patience=50,\n",
    "                   verbose=0)\n",
    "history = model.fit(X, Y, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1771e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "# # get model accuracy # #\n",
    "##########################\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "######################\n",
    "# # get model loss # #\n",
    "######################\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d2413",
   "metadata": {},
   "source": [
    "#### SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1247bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # save model # #\n",
    "##################\n",
    "model.model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12799eac",
   "metadata": {},
   "source": [
    "# LIVE TESTING\n",
    "> Live test with new dataset to check if model function as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0074460",
   "metadata": {},
   "source": [
    "#### LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1da540d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# # load model # #\n",
    "##################\n",
    "\n",
    "# model = create_model()\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f0646",
   "metadata": {},
   "source": [
    "#### LOAD DATA\n",
    "- Import new dataset to verify the model is able to predict accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29bff51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Password</th>\n",
       "      <th>T2-D|0</th>\n",
       "      <th>T2-I|0+1</th>\n",
       "      <th>T2-PF|0+1</th>\n",
       "      <th>T2-RF|0+1</th>\n",
       "      <th>T2-NG|0+1</th>\n",
       "      <th>T2-D|1</th>\n",
       "      <th>T2-I|1+2</th>\n",
       "      <th>T2-PF|1+2</th>\n",
       "      <th>T2-RF|1+2</th>\n",
       "      <th>T2-NG|1+2</th>\n",
       "      <th>T2-D|2</th>\n",
       "      <th>T2-I|2+3</th>\n",
       "      <th>T2-PF|2+3</th>\n",
       "      <th>T2-RF|2+3</th>\n",
       "      <th>T2-NG|2+3</th>\n",
       "      <th>T2-D|3</th>\n",
       "      <th>T2-I|3+4</th>\n",
       "      <th>T2-PF|3+4</th>\n",
       "      <th>T2-RF|3+4</th>\n",
       "      <th>T2-NG|3+4</th>\n",
       "      <th>T2-D|4</th>\n",
       "      <th>T2-I|4+5</th>\n",
       "      <th>T2-PF|4+5</th>\n",
       "      <th>T2-RF|4+5</th>\n",
       "      <th>T2-NG|4+5</th>\n",
       "      <th>T2-D|5</th>\n",
       "      <th>T2-I|5+6</th>\n",
       "      <th>T2-PF|5+6</th>\n",
       "      <th>T2-RF|5+6</th>\n",
       "      <th>T2-NG|5+6</th>\n",
       "      <th>T2-D|6</th>\n",
       "      <th>T2-I|6+7</th>\n",
       "      <th>T2-PF|6+7</th>\n",
       "      <th>T2-RF|6+7</th>\n",
       "      <th>T2-NG|6+7</th>\n",
       "      <th>T2-D|7</th>\n",
       "      <th>T2-D|S</th>\n",
       "      <th>T2-I|S</th>\n",
       "      <th>T2-PF|S</th>\n",
       "      <th>T2-RF|S</th>\n",
       "      <th>T2-NG|S</th>\n",
       "      <th>T2-D|M</th>\n",
       "      <th>T2-I|M</th>\n",
       "      <th>T2-PF|M</th>\n",
       "      <th>T2-RF|M</th>\n",
       "      <th>T2-DT-M</th>\n",
       "      <th>T2-D|VAR</th>\n",
       "      <th>T2-I|VAR</th>\n",
       "      <th>T2-PF|VAR</th>\n",
       "      <th>T2-RF|VAR</th>\n",
       "      <th>T2-DT-VAR</th>\n",
       "      <th>T2-D|SD</th>\n",
       "      <th>T2-I|SD</th>\n",
       "      <th>T2-PF|SD</th>\n",
       "      <th>T2-RF|SD</th>\n",
       "      <th>T2-NG|SD</th>\n",
       "      <th>T3-I|0+2</th>\n",
       "      <th>T3-PF|0+2</th>\n",
       "      <th>T3-RF|0+2</th>\n",
       "      <th>T3-NG|0+2</th>\n",
       "      <th>T3-I|1+3</th>\n",
       "      <th>T3-PF|1+3</th>\n",
       "      <th>T3-RF|1+3</th>\n",
       "      <th>T3-NG|1+3</th>\n",
       "      <th>T3-I|2+4</th>\n",
       "      <th>T3-PF|2+4</th>\n",
       "      <th>T3-RF|2+4</th>\n",
       "      <th>T3-NG|2+4</th>\n",
       "      <th>T3-I|3+5</th>\n",
       "      <th>T3-PF|3+5</th>\n",
       "      <th>T3-RF|3+5</th>\n",
       "      <th>T3-NG|3+5</th>\n",
       "      <th>T3-I|4+6</th>\n",
       "      <th>T3-PF|4+6</th>\n",
       "      <th>T3-RF|4+6</th>\n",
       "      <th>T3-NG|4+6</th>\n",
       "      <th>T3-I|5+7</th>\n",
       "      <th>T3-PF|5+7</th>\n",
       "      <th>T3-RF|5+7</th>\n",
       "      <th>T3-NG|5+7</th>\n",
       "      <th>T3-I|S</th>\n",
       "      <th>T3-PF|S</th>\n",
       "      <th>T3-RF|S</th>\n",
       "      <th>T3-NG|S</th>\n",
       "      <th>T3-I|M</th>\n",
       "      <th>T3-PF|M</th>\n",
       "      <th>T3-RF|M</th>\n",
       "      <th>T3-NG|M</th>\n",
       "      <th>T3-I|VAR</th>\n",
       "      <th>T3-PF|VAR</th>\n",
       "      <th>T3-RF|VAR</th>\n",
       "      <th>T3-NG|VAR</th>\n",
       "      <th>T3-I|SD</th>\n",
       "      <th>T3-PF|SD</th>\n",
       "      <th>T3-RF|SD</th>\n",
       "      <th>T3-NG|SD</th>\n",
       "      <th>T4-I|0+3</th>\n",
       "      <th>T4-PF|0+3</th>\n",
       "      <th>T4-RF|0+3</th>\n",
       "      <th>T4-NG|0+3</th>\n",
       "      <th>T4-I|1+4</th>\n",
       "      <th>T4-PF|1+4</th>\n",
       "      <th>T4-RF|1+4</th>\n",
       "      <th>T4-NG|1+4</th>\n",
       "      <th>T4-I|2+5</th>\n",
       "      <th>T4-PF|2+5</th>\n",
       "      <th>T4-RF|2+5</th>\n",
       "      <th>T4-NG|2+5</th>\n",
       "      <th>T4-I|3+6</th>\n",
       "      <th>T4-PF|3+6</th>\n",
       "      <th>T4-RF|3+6</th>\n",
       "      <th>T4-NG|3+6</th>\n",
       "      <th>T4-I|4+7</th>\n",
       "      <th>T4-PF|4+7</th>\n",
       "      <th>T4-RF|4+7</th>\n",
       "      <th>T4-NG|4+7</th>\n",
       "      <th>T4-I|S</th>\n",
       "      <th>T4-PF|S</th>\n",
       "      <th>T4-RF|S</th>\n",
       "      <th>T4-NG|S</th>\n",
       "      <th>T4-I|M</th>\n",
       "      <th>T4-PF|M</th>\n",
       "      <th>T4-RF|M</th>\n",
       "      <th>T4-NG|M</th>\n",
       "      <th>T4-I|VAR</th>\n",
       "      <th>T4-PF|VAR</th>\n",
       "      <th>T4-RF|VAR</th>\n",
       "      <th>T4-NG|VAR</th>\n",
       "      <th>T4-I|SD</th>\n",
       "      <th>T4-PF|SD</th>\n",
       "      <th>T4-RF|SD</th>\n",
       "      <th>T4-NG|SD</th>\n",
       "      <th>T5-I|0+4</th>\n",
       "      <th>T5-PF|0+4</th>\n",
       "      <th>T5-RF|0+4</th>\n",
       "      <th>T5-NG|0+4</th>\n",
       "      <th>T5-I|1+5</th>\n",
       "      <th>T5-PF|1+5</th>\n",
       "      <th>T5-RF|1+5</th>\n",
       "      <th>T5-NG|1+5</th>\n",
       "      <th>T5-I|2+6</th>\n",
       "      <th>T5-PF|2+6</th>\n",
       "      <th>T5-RF|2+6</th>\n",
       "      <th>T5-NG|2+6</th>\n",
       "      <th>T5-I|3+7</th>\n",
       "      <th>T5-PF|3+7</th>\n",
       "      <th>T5-RF|3+7</th>\n",
       "      <th>T5-NG|3+7</th>\n",
       "      <th>T5-I|S</th>\n",
       "      <th>T5-PF|S</th>\n",
       "      <th>T5-RF|S</th>\n",
       "      <th>T5-NG|S</th>\n",
       "      <th>T5-I|M</th>\n",
       "      <th>T5-PF|M</th>\n",
       "      <th>T5-RF|M</th>\n",
       "      <th>T5-NG|M</th>\n",
       "      <th>T5-I|VAR</th>\n",
       "      <th>T5-PF|VAR</th>\n",
       "      <th>T5-RF|VAR</th>\n",
       "      <th>T5-NG|VAR</th>\n",
       "      <th>T5-I|SD</th>\n",
       "      <th>T5-PF|SD</th>\n",
       "      <th>T5-RF|SD</th>\n",
       "      <th>T5-NG|SD</th>\n",
       "      <th>T6-I|0+5</th>\n",
       "      <th>T6-PF|0+5</th>\n",
       "      <th>T6-RF|0+5</th>\n",
       "      <th>T6-NG|0+5</th>\n",
       "      <th>T6-I|1+6</th>\n",
       "      <th>T6-PF|1+6</th>\n",
       "      <th>T6-RF|1+6</th>\n",
       "      <th>T6-NG|1+6</th>\n",
       "      <th>T6-I|2+7</th>\n",
       "      <th>T6-PF|2+7</th>\n",
       "      <th>T6-RF|2+7</th>\n",
       "      <th>T6-NG|2+7</th>\n",
       "      <th>T6-I|S</th>\n",
       "      <th>T6-PF|S</th>\n",
       "      <th>T6-RF|S</th>\n",
       "      <th>T6-NG|S</th>\n",
       "      <th>T6-I|M</th>\n",
       "      <th>T6-PF|M</th>\n",
       "      <th>T6-RF|M</th>\n",
       "      <th>T6-NG|M</th>\n",
       "      <th>T6-I|VAR</th>\n",
       "      <th>T6-PF|VAR</th>\n",
       "      <th>T6-RF|VAR</th>\n",
       "      <th>T6-NG|VAR</th>\n",
       "      <th>T6-I|SD</th>\n",
       "      <th>T6-PF|SD</th>\n",
       "      <th>T6-RF|SD</th>\n",
       "      <th>T6-NG|SD</th>\n",
       "      <th>T7-I|0+6</th>\n",
       "      <th>T7-PF|0+6</th>\n",
       "      <th>T7-RF|0+6</th>\n",
       "      <th>T7-NG|0+6</th>\n",
       "      <th>T7-I|1+7</th>\n",
       "      <th>T7-PF|1+7</th>\n",
       "      <th>T7-RF|1+7</th>\n",
       "      <th>T7-NG|1+7</th>\n",
       "      <th>T7-I|S</th>\n",
       "      <th>T7-PF|S</th>\n",
       "      <th>T7-RF|S</th>\n",
       "      <th>T7-NG|S</th>\n",
       "      <th>T7-I|M</th>\n",
       "      <th>T7-PF|M</th>\n",
       "      <th>T7-RF|M</th>\n",
       "      <th>T7-NG|M</th>\n",
       "      <th>T7-I|VAR</th>\n",
       "      <th>T7-PF|VAR</th>\n",
       "      <th>T7-RF|VAR</th>\n",
       "      <th>T7-NG|VAR</th>\n",
       "      <th>T7-I|SD</th>\n",
       "      <th>T7-PF|SD</th>\n",
       "      <th>T7-RF|SD</th>\n",
       "      <th>T7-NG|SD</th>\n",
       "      <th>T8-I|0+7</th>\n",
       "      <th>T8-PF|0+7</th>\n",
       "      <th>T8-RF|0+7</th>\n",
       "      <th>T8-NG|0+7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andy</td>\n",
       "      <td>dEcisi0n</td>\n",
       "      <td>0.112628</td>\n",
       "      <td>0.079001</td>\n",
       "      <td>0.191629</td>\n",
       "      <td>0.189652</td>\n",
       "      <td>0.302280</td>\n",
       "      <td>0.110651</td>\n",
       "      <td>0.057247</td>\n",
       "      <td>0.167898</td>\n",
       "      <td>0.146393</td>\n",
       "      <td>0.257044</td>\n",
       "      <td>0.089146</td>\n",
       "      <td>0.056419</td>\n",
       "      <td>0.145565</td>\n",
       "      <td>0.158604</td>\n",
       "      <td>0.247750</td>\n",
       "      <td>0.102185</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>0.146969</td>\n",
       "      <td>0.169310</td>\n",
       "      <td>0.271495</td>\n",
       "      <td>0.124527</td>\n",
       "      <td>-0.045218</td>\n",
       "      <td>0.079309</td>\n",
       "      <td>0.043676</td>\n",
       "      <td>0.168202</td>\n",
       "      <td>0.088894</td>\n",
       "      <td>0.327517</td>\n",
       "      <td>0.416411</td>\n",
       "      <td>0.440134</td>\n",
       "      <td>0.529028</td>\n",
       "      <td>0.112617</td>\n",
       "      <td>-0.011089</td>\n",
       "      <td>0.101528</td>\n",
       "      <td>0.054103</td>\n",
       "      <td>0.166720</td>\n",
       "      <td>0.065192</td>\n",
       "      <td>0.805840</td>\n",
       "      <td>0.508661</td>\n",
       "      <td>1.249309</td>\n",
       "      <td>1.201873</td>\n",
       "      <td>1.942520</td>\n",
       "      <td>0.100730</td>\n",
       "      <td>0.072666</td>\n",
       "      <td>0.178473</td>\n",
       "      <td>0.171696</td>\n",
       "      <td>0.277503</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.014530</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.017236</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.018849</td>\n",
       "      <td>0.120540</td>\n",
       "      <td>0.111601</td>\n",
       "      <td>0.131286</td>\n",
       "      <td>0.122092</td>\n",
       "      <td>0.246899</td>\n",
       "      <td>0.359527</td>\n",
       "      <td>0.336045</td>\n",
       "      <td>0.448673</td>\n",
       "      <td>0.202812</td>\n",
       "      <td>0.313463</td>\n",
       "      <td>0.304997</td>\n",
       "      <td>0.415648</td>\n",
       "      <td>0.203387</td>\n",
       "      <td>0.292533</td>\n",
       "      <td>0.327914</td>\n",
       "      <td>0.417060</td>\n",
       "      <td>0.124092</td>\n",
       "      <td>0.226277</td>\n",
       "      <td>0.212986</td>\n",
       "      <td>0.315171</td>\n",
       "      <td>0.371193</td>\n",
       "      <td>0.495719</td>\n",
       "      <td>0.483810</td>\n",
       "      <td>0.608336</td>\n",
       "      <td>0.429045</td>\n",
       "      <td>0.517939</td>\n",
       "      <td>0.494237</td>\n",
       "      <td>0.583131</td>\n",
       "      <td>1.577429</td>\n",
       "      <td>2.205460</td>\n",
       "      <td>2.159989</td>\n",
       "      <td>2.788020</td>\n",
       "      <td>0.262905</td>\n",
       "      <td>0.367577</td>\n",
       "      <td>0.359998</td>\n",
       "      <td>0.464670</td>\n",
       "      <td>0.013202</td>\n",
       "      <td>0.013524</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.114898</td>\n",
       "      <td>0.116292</td>\n",
       "      <td>0.109170</td>\n",
       "      <td>0.111309</td>\n",
       "      <td>0.392464</td>\n",
       "      <td>0.505092</td>\n",
       "      <td>0.494649</td>\n",
       "      <td>0.607277</td>\n",
       "      <td>0.349780</td>\n",
       "      <td>0.460432</td>\n",
       "      <td>0.474307</td>\n",
       "      <td>0.584958</td>\n",
       "      <td>0.282696</td>\n",
       "      <td>0.371842</td>\n",
       "      <td>0.371590</td>\n",
       "      <td>0.460736</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>0.642688</td>\n",
       "      <td>0.653120</td>\n",
       "      <td>0.755305</td>\n",
       "      <td>0.472721</td>\n",
       "      <td>0.597248</td>\n",
       "      <td>0.537913</td>\n",
       "      <td>0.662440</td>\n",
       "      <td>2.038165</td>\n",
       "      <td>2.577302</td>\n",
       "      <td>2.531579</td>\n",
       "      <td>3.070716</td>\n",
       "      <td>0.407633</td>\n",
       "      <td>0.515460</td>\n",
       "      <td>0.506316</td>\n",
       "      <td>0.614143</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.011659</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.101338</td>\n",
       "      <td>0.107979</td>\n",
       "      <td>0.102301</td>\n",
       "      <td>0.108042</td>\n",
       "      <td>0.539433</td>\n",
       "      <td>0.652061</td>\n",
       "      <td>0.663960</td>\n",
       "      <td>0.776587</td>\n",
       "      <td>0.429089</td>\n",
       "      <td>0.539740</td>\n",
       "      <td>0.517983</td>\n",
       "      <td>0.628634</td>\n",
       "      <td>0.699107</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.811724</td>\n",
       "      <td>0.900870</td>\n",
       "      <td>0.642031</td>\n",
       "      <td>0.744216</td>\n",
       "      <td>0.707223</td>\n",
       "      <td>0.809408</td>\n",
       "      <td>2.309660</td>\n",
       "      <td>2.724270</td>\n",
       "      <td>2.700890</td>\n",
       "      <td>3.115500</td>\n",
       "      <td>0.577415</td>\n",
       "      <td>0.681068</td>\n",
       "      <td>0.675222</td>\n",
       "      <td>0.778875</td>\n",
       "      <td>0.014143</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.012798</td>\n",
       "      <td>0.118922</td>\n",
       "      <td>0.109987</td>\n",
       "      <td>0.121803</td>\n",
       "      <td>0.113126</td>\n",
       "      <td>0.618741</td>\n",
       "      <td>0.731369</td>\n",
       "      <td>0.707635</td>\n",
       "      <td>0.820263</td>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.956151</td>\n",
       "      <td>0.958117</td>\n",
       "      <td>1.068768</td>\n",
       "      <td>0.800635</td>\n",
       "      <td>0.889781</td>\n",
       "      <td>0.865827</td>\n",
       "      <td>0.954973</td>\n",
       "      <td>2.264876</td>\n",
       "      <td>2.577302</td>\n",
       "      <td>2.531579</td>\n",
       "      <td>2.844004</td>\n",
       "      <td>0.754959</td>\n",
       "      <td>0.859101</td>\n",
       "      <td>0.843860</td>\n",
       "      <td>0.948001</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>0.120082</td>\n",
       "      <td>0.115489</td>\n",
       "      <td>0.126678</td>\n",
       "      <td>0.124399</td>\n",
       "      <td>1.035152</td>\n",
       "      <td>1.147780</td>\n",
       "      <td>1.147769</td>\n",
       "      <td>1.260397</td>\n",
       "      <td>0.947028</td>\n",
       "      <td>1.057679</td>\n",
       "      <td>1.012220</td>\n",
       "      <td>1.122871</td>\n",
       "      <td>1.982180</td>\n",
       "      <td>2.205460</td>\n",
       "      <td>2.159989</td>\n",
       "      <td>2.383269</td>\n",
       "      <td>0.991090</td>\n",
       "      <td>1.102730</td>\n",
       "      <td>1.079995</td>\n",
       "      <td>1.191634</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.062313</td>\n",
       "      <td>0.063711</td>\n",
       "      <td>0.095848</td>\n",
       "      <td>0.097245</td>\n",
       "      <td>1.136681</td>\n",
       "      <td>1.249309</td>\n",
       "      <td>1.201873</td>\n",
       "      <td>1.314501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andy</td>\n",
       "      <td>dEcisi0n</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.191321</td>\n",
       "      <td>0.294262</td>\n",
       "      <td>0.280651</td>\n",
       "      <td>0.383592</td>\n",
       "      <td>0.089330</td>\n",
       "      <td>0.089771</td>\n",
       "      <td>0.179101</td>\n",
       "      <td>0.169192</td>\n",
       "      <td>0.258522</td>\n",
       "      <td>0.079421</td>\n",
       "      <td>0.078084</td>\n",
       "      <td>0.157506</td>\n",
       "      <td>0.156776</td>\n",
       "      <td>0.236197</td>\n",
       "      <td>0.078692</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.090702</td>\n",
       "      <td>0.110938</td>\n",
       "      <td>0.189630</td>\n",
       "      <td>0.098928</td>\n",
       "      <td>-0.022104</td>\n",
       "      <td>0.076824</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.121828</td>\n",
       "      <td>0.045004</td>\n",
       "      <td>0.136034</td>\n",
       "      <td>0.181038</td>\n",
       "      <td>0.260071</td>\n",
       "      <td>0.305074</td>\n",
       "      <td>0.124036</td>\n",
       "      <td>-0.011227</td>\n",
       "      <td>0.112809</td>\n",
       "      <td>0.066895</td>\n",
       "      <td>0.190931</td>\n",
       "      <td>0.078121</td>\n",
       "      <td>0.696474</td>\n",
       "      <td>0.473890</td>\n",
       "      <td>1.092242</td>\n",
       "      <td>1.067423</td>\n",
       "      <td>1.685775</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>0.067699</td>\n",
       "      <td>0.156035</td>\n",
       "      <td>0.152489</td>\n",
       "      <td>0.240825</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.023122</td>\n",
       "      <td>0.079522</td>\n",
       "      <td>0.073798</td>\n",
       "      <td>0.094994</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>0.370422</td>\n",
       "      <td>0.473363</td>\n",
       "      <td>0.449843</td>\n",
       "      <td>0.552784</td>\n",
       "      <td>0.247276</td>\n",
       "      <td>0.336607</td>\n",
       "      <td>0.325968</td>\n",
       "      <td>0.415298</td>\n",
       "      <td>0.168787</td>\n",
       "      <td>0.248208</td>\n",
       "      <td>0.267715</td>\n",
       "      <td>0.347136</td>\n",
       "      <td>0.088834</td>\n",
       "      <td>0.167526</td>\n",
       "      <td>0.133838</td>\n",
       "      <td>0.212530</td>\n",
       "      <td>0.158934</td>\n",
       "      <td>0.257862</td>\n",
       "      <td>0.282970</td>\n",
       "      <td>0.381898</td>\n",
       "      <td>0.248844</td>\n",
       "      <td>0.293848</td>\n",
       "      <td>0.326965</td>\n",
       "      <td>0.371969</td>\n",
       "      <td>1.283097</td>\n",
       "      <td>1.777413</td>\n",
       "      <td>1.787299</td>\n",
       "      <td>2.281615</td>\n",
       "      <td>0.213849</td>\n",
       "      <td>0.296235</td>\n",
       "      <td>0.297883</td>\n",
       "      <td>0.380269</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.097501</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.102732</td>\n",
       "      <td>0.109813</td>\n",
       "      <td>0.527927</td>\n",
       "      <td>0.630868</td>\n",
       "      <td>0.606619</td>\n",
       "      <td>0.709560</td>\n",
       "      <td>0.337978</td>\n",
       "      <td>0.427309</td>\n",
       "      <td>0.436906</td>\n",
       "      <td>0.526237</td>\n",
       "      <td>0.245610</td>\n",
       "      <td>0.325032</td>\n",
       "      <td>0.290614</td>\n",
       "      <td>0.370035</td>\n",
       "      <td>0.269872</td>\n",
       "      <td>0.348564</td>\n",
       "      <td>0.393909</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.271744</td>\n",
       "      <td>0.370672</td>\n",
       "      <td>0.349865</td>\n",
       "      <td>0.448793</td>\n",
       "      <td>1.653132</td>\n",
       "      <td>2.102444</td>\n",
       "      <td>2.077914</td>\n",
       "      <td>2.527226</td>\n",
       "      <td>0.330626</td>\n",
       "      <td>0.420489</td>\n",
       "      <td>0.415583</td>\n",
       "      <td>0.505445</td>\n",
       "      <td>0.013342</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.115507</td>\n",
       "      <td>0.123565</td>\n",
       "      <td>0.119745</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.618630</td>\n",
       "      <td>0.721570</td>\n",
       "      <td>0.717558</td>\n",
       "      <td>0.820498</td>\n",
       "      <td>0.414802</td>\n",
       "      <td>0.504133</td>\n",
       "      <td>0.459806</td>\n",
       "      <td>0.549136</td>\n",
       "      <td>0.426649</td>\n",
       "      <td>0.506070</td>\n",
       "      <td>0.550685</td>\n",
       "      <td>0.630106</td>\n",
       "      <td>0.382682</td>\n",
       "      <td>0.461374</td>\n",
       "      <td>0.460803</td>\n",
       "      <td>0.539495</td>\n",
       "      <td>1.842762</td>\n",
       "      <td>2.193147</td>\n",
       "      <td>2.188852</td>\n",
       "      <td>2.539236</td>\n",
       "      <td>0.460691</td>\n",
       "      <td>0.548287</td>\n",
       "      <td>0.547213</td>\n",
       "      <td>0.634809</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.106919</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>0.121293</td>\n",
       "      <td>0.130291</td>\n",
       "      <td>0.695453</td>\n",
       "      <td>0.798394</td>\n",
       "      <td>0.740457</td>\n",
       "      <td>0.843398</td>\n",
       "      <td>0.595840</td>\n",
       "      <td>0.685171</td>\n",
       "      <td>0.719877</td>\n",
       "      <td>0.809207</td>\n",
       "      <td>0.539458</td>\n",
       "      <td>0.618879</td>\n",
       "      <td>0.617580</td>\n",
       "      <td>0.697001</td>\n",
       "      <td>1.830752</td>\n",
       "      <td>2.102444</td>\n",
       "      <td>2.077914</td>\n",
       "      <td>2.349606</td>\n",
       "      <td>0.610251</td>\n",
       "      <td>0.700815</td>\n",
       "      <td>0.692638</td>\n",
       "      <td>0.783202</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.078990</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>0.065812</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>0.876492</td>\n",
       "      <td>0.979433</td>\n",
       "      <td>1.000528</td>\n",
       "      <td>1.103469</td>\n",
       "      <td>0.708650</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.786771</td>\n",
       "      <td>0.876102</td>\n",
       "      <td>1.585142</td>\n",
       "      <td>1.777413</td>\n",
       "      <td>1.787299</td>\n",
       "      <td>1.979570</td>\n",
       "      <td>0.792571</td>\n",
       "      <td>0.888706</td>\n",
       "      <td>0.893650</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.016462</td>\n",
       "      <td>0.022846</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.118682</td>\n",
       "      <td>0.128306</td>\n",
       "      <td>0.151149</td>\n",
       "      <td>0.160773</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>1.092242</td>\n",
       "      <td>1.067423</td>\n",
       "      <td>1.170363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andy</td>\n",
       "      <td>dEcisi0n</td>\n",
       "      <td>0.114735</td>\n",
       "      <td>0.099664</td>\n",
       "      <td>0.214399</td>\n",
       "      <td>0.212517</td>\n",
       "      <td>0.327251</td>\n",
       "      <td>0.112853</td>\n",
       "      <td>0.101198</td>\n",
       "      <td>0.214051</td>\n",
       "      <td>0.191127</td>\n",
       "      <td>0.303980</td>\n",
       "      <td>0.089929</td>\n",
       "      <td>0.035299</td>\n",
       "      <td>0.125228</td>\n",
       "      <td>0.114423</td>\n",
       "      <td>0.204352</td>\n",
       "      <td>0.079124</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.083662</td>\n",
       "      <td>0.122118</td>\n",
       "      <td>0.201242</td>\n",
       "      <td>0.117580</td>\n",
       "      <td>-0.054626</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>0.023402</td>\n",
       "      <td>0.140982</td>\n",
       "      <td>0.078028</td>\n",
       "      <td>0.112980</td>\n",
       "      <td>0.191008</td>\n",
       "      <td>0.270615</td>\n",
       "      <td>0.348643</td>\n",
       "      <td>0.157635</td>\n",
       "      <td>-0.045640</td>\n",
       "      <td>0.111995</td>\n",
       "      <td>0.033439</td>\n",
       "      <td>0.191074</td>\n",
       "      <td>0.079080</td>\n",
       "      <td>0.828963</td>\n",
       "      <td>0.253412</td>\n",
       "      <td>1.003296</td>\n",
       "      <td>0.967641</td>\n",
       "      <td>1.717525</td>\n",
       "      <td>0.103620</td>\n",
       "      <td>0.036202</td>\n",
       "      <td>0.143328</td>\n",
       "      <td>0.138234</td>\n",
       "      <td>0.245361</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.027687</td>\n",
       "      <td>0.070826</td>\n",
       "      <td>0.062790</td>\n",
       "      <td>0.092047</td>\n",
       "      <td>0.079874</td>\n",
       "      <td>0.313715</td>\n",
       "      <td>0.428449</td>\n",
       "      <td>0.403644</td>\n",
       "      <td>0.518378</td>\n",
       "      <td>0.226426</td>\n",
       "      <td>0.339279</td>\n",
       "      <td>0.305550</td>\n",
       "      <td>0.418403</td>\n",
       "      <td>0.118961</td>\n",
       "      <td>0.208890</td>\n",
       "      <td>0.236541</td>\n",
       "      <td>0.326470</td>\n",
       "      <td>0.067492</td>\n",
       "      <td>0.146616</td>\n",
       "      <td>0.145520</td>\n",
       "      <td>0.224644</td>\n",
       "      <td>0.136382</td>\n",
       "      <td>0.253962</td>\n",
       "      <td>0.294017</td>\n",
       "      <td>0.411597</td>\n",
       "      <td>0.224975</td>\n",
       "      <td>0.303003</td>\n",
       "      <td>0.304054</td>\n",
       "      <td>0.382082</td>\n",
       "      <td>1.087950</td>\n",
       "      <td>1.680199</td>\n",
       "      <td>1.689326</td>\n",
       "      <td>2.281574</td>\n",
       "      <td>0.181325</td>\n",
       "      <td>0.280033</td>\n",
       "      <td>0.281554</td>\n",
       "      <td>0.380262</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.089815</td>\n",
       "      <td>0.099605</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.098617</td>\n",
       "      <td>0.438943</td>\n",
       "      <td>0.553678</td>\n",
       "      <td>0.518067</td>\n",
       "      <td>0.632802</td>\n",
       "      <td>0.310088</td>\n",
       "      <td>0.422941</td>\n",
       "      <td>0.427668</td>\n",
       "      <td>0.540521</td>\n",
       "      <td>0.181915</td>\n",
       "      <td>0.271844</td>\n",
       "      <td>0.259943</td>\n",
       "      <td>0.349872</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.337624</td>\n",
       "      <td>0.416135</td>\n",
       "      <td>0.495259</td>\n",
       "      <td>0.248377</td>\n",
       "      <td>0.365957</td>\n",
       "      <td>0.327456</td>\n",
       "      <td>0.445036</td>\n",
       "      <td>1.437822</td>\n",
       "      <td>1.952043</td>\n",
       "      <td>1.949269</td>\n",
       "      <td>2.463490</td>\n",
       "      <td>0.287564</td>\n",
       "      <td>0.390409</td>\n",
       "      <td>0.389854</td>\n",
       "      <td>0.492698</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.011148</td>\n",
       "      <td>0.096131</td>\n",
       "      <td>0.106251</td>\n",
       "      <td>0.099158</td>\n",
       "      <td>0.105586</td>\n",
       "      <td>0.522604</td>\n",
       "      <td>0.637339</td>\n",
       "      <td>0.640185</td>\n",
       "      <td>0.754920</td>\n",
       "      <td>0.373042</td>\n",
       "      <td>0.485895</td>\n",
       "      <td>0.451070</td>\n",
       "      <td>0.563923</td>\n",
       "      <td>0.372923</td>\n",
       "      <td>0.462852</td>\n",
       "      <td>0.530558</td>\n",
       "      <td>0.620487</td>\n",
       "      <td>0.370495</td>\n",
       "      <td>0.449619</td>\n",
       "      <td>0.449574</td>\n",
       "      <td>0.528698</td>\n",
       "      <td>1.639064</td>\n",
       "      <td>2.035705</td>\n",
       "      <td>2.071387</td>\n",
       "      <td>2.468027</td>\n",
       "      <td>0.409766</td>\n",
       "      <td>0.508926</td>\n",
       "      <td>0.517847</td>\n",
       "      <td>0.617007</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>0.086911</td>\n",
       "      <td>0.089904</td>\n",
       "      <td>0.099412</td>\n",
       "      <td>0.585559</td>\n",
       "      <td>0.700294</td>\n",
       "      <td>0.663586</td>\n",
       "      <td>0.778321</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>0.676903</td>\n",
       "      <td>0.721685</td>\n",
       "      <td>0.834538</td>\n",
       "      <td>0.484918</td>\n",
       "      <td>0.574847</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.653926</td>\n",
       "      <td>1.634526</td>\n",
       "      <td>1.952043</td>\n",
       "      <td>1.949269</td>\n",
       "      <td>2.266785</td>\n",
       "      <td>0.544842</td>\n",
       "      <td>0.650681</td>\n",
       "      <td>0.649756</td>\n",
       "      <td>0.755595</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.052999</td>\n",
       "      <td>0.066708</td>\n",
       "      <td>0.079748</td>\n",
       "      <td>0.092426</td>\n",
       "      <td>0.776567</td>\n",
       "      <td>0.891301</td>\n",
       "      <td>0.934201</td>\n",
       "      <td>1.048936</td>\n",
       "      <td>0.676045</td>\n",
       "      <td>0.788898</td>\n",
       "      <td>0.755124</td>\n",
       "      <td>0.867977</td>\n",
       "      <td>1.452611</td>\n",
       "      <td>1.680199</td>\n",
       "      <td>1.689326</td>\n",
       "      <td>1.916914</td>\n",
       "      <td>0.726306</td>\n",
       "      <td>0.840099</td>\n",
       "      <td>0.844663</td>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>0.071080</td>\n",
       "      <td>0.072410</td>\n",
       "      <td>0.126627</td>\n",
       "      <td>0.127957</td>\n",
       "      <td>0.888561</td>\n",
       "      <td>1.003296</td>\n",
       "      <td>0.967641</td>\n",
       "      <td>1.082376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andy</td>\n",
       "      <td>dEcisi0n</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.203218</td>\n",
       "      <td>0.178590</td>\n",
       "      <td>0.292377</td>\n",
       "      <td>0.089159</td>\n",
       "      <td>0.057329</td>\n",
       "      <td>0.146488</td>\n",
       "      <td>0.157044</td>\n",
       "      <td>0.246203</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.110943</td>\n",
       "      <td>0.078616</td>\n",
       "      <td>0.178331</td>\n",
       "      <td>0.067387</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.068380</td>\n",
       "      <td>0.126114</td>\n",
       "      <td>0.193501</td>\n",
       "      <td>0.125121</td>\n",
       "      <td>-0.035574</td>\n",
       "      <td>0.089547</td>\n",
       "      <td>0.044653</td>\n",
       "      <td>0.169775</td>\n",
       "      <td>0.080227</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.203237</td>\n",
       "      <td>0.236368</td>\n",
       "      <td>0.316595</td>\n",
       "      <td>0.113358</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>0.124347</td>\n",
       "      <td>0.066195</td>\n",
       "      <td>0.179554</td>\n",
       "      <td>0.055207</td>\n",
       "      <td>0.743962</td>\n",
       "      <td>0.257405</td>\n",
       "      <td>0.946160</td>\n",
       "      <td>0.887580</td>\n",
       "      <td>1.576335</td>\n",
       "      <td>0.092995</td>\n",
       "      <td>0.036772</td>\n",
       "      <td>0.135166</td>\n",
       "      <td>0.126797</td>\n",
       "      <td>0.225191</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.052660</td>\n",
       "      <td>0.068733</td>\n",
       "      <td>0.060089</td>\n",
       "      <td>0.235919</td>\n",
       "      <td>0.349706</td>\n",
       "      <td>0.335634</td>\n",
       "      <td>0.449421</td>\n",
       "      <td>0.168272</td>\n",
       "      <td>0.257432</td>\n",
       "      <td>0.235660</td>\n",
       "      <td>0.324819</td>\n",
       "      <td>0.079608</td>\n",
       "      <td>0.179323</td>\n",
       "      <td>0.204729</td>\n",
       "      <td>0.304444</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.157927</td>\n",
       "      <td>0.170767</td>\n",
       "      <td>0.238154</td>\n",
       "      <td>0.167663</td>\n",
       "      <td>0.292784</td>\n",
       "      <td>0.281021</td>\n",
       "      <td>0.406143</td>\n",
       "      <td>0.247356</td>\n",
       "      <td>0.327584</td>\n",
       "      <td>0.302563</td>\n",
       "      <td>0.382791</td>\n",
       "      <td>0.989359</td>\n",
       "      <td>1.564756</td>\n",
       "      <td>1.530375</td>\n",
       "      <td>2.105772</td>\n",
       "      <td>0.164893</td>\n",
       "      <td>0.260793</td>\n",
       "      <td>0.255063</td>\n",
       "      <td>0.350962</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.070237</td>\n",
       "      <td>0.078256</td>\n",
       "      <td>0.062350</td>\n",
       "      <td>0.076583</td>\n",
       "      <td>0.346863</td>\n",
       "      <td>0.460649</td>\n",
       "      <td>0.414250</td>\n",
       "      <td>0.528037</td>\n",
       "      <td>0.236652</td>\n",
       "      <td>0.325811</td>\n",
       "      <td>0.361773</td>\n",
       "      <td>0.450933</td>\n",
       "      <td>0.169155</td>\n",
       "      <td>0.268870</td>\n",
       "      <td>0.249383</td>\n",
       "      <td>0.349098</td>\n",
       "      <td>0.293777</td>\n",
       "      <td>0.361164</td>\n",
       "      <td>0.407135</td>\n",
       "      <td>0.474522</td>\n",
       "      <td>0.292010</td>\n",
       "      <td>0.417131</td>\n",
       "      <td>0.347217</td>\n",
       "      <td>0.472338</td>\n",
       "      <td>1.338457</td>\n",
       "      <td>1.833626</td>\n",
       "      <td>1.779758</td>\n",
       "      <td>2.274927</td>\n",
       "      <td>0.267691</td>\n",
       "      <td>0.366725</td>\n",
       "      <td>0.355952</td>\n",
       "      <td>0.454985</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.067477</td>\n",
       "      <td>0.075238</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.065666</td>\n",
       "      <td>0.415242</td>\n",
       "      <td>0.529029</td>\n",
       "      <td>0.540364</td>\n",
       "      <td>0.654150</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>0.415359</td>\n",
       "      <td>0.406427</td>\n",
       "      <td>0.495586</td>\n",
       "      <td>0.372392</td>\n",
       "      <td>0.472107</td>\n",
       "      <td>0.485751</td>\n",
       "      <td>0.585466</td>\n",
       "      <td>0.418123</td>\n",
       "      <td>0.485511</td>\n",
       "      <td>0.473330</td>\n",
       "      <td>0.540718</td>\n",
       "      <td>1.531958</td>\n",
       "      <td>1.902006</td>\n",
       "      <td>1.905872</td>\n",
       "      <td>2.275920</td>\n",
       "      <td>0.382989</td>\n",
       "      <td>0.475501</td>\n",
       "      <td>0.476468</td>\n",
       "      <td>0.568980</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.043251</td>\n",
       "      <td>0.046883</td>\n",
       "      <td>0.055029</td>\n",
       "      <td>0.067605</td>\n",
       "      <td>0.504790</td>\n",
       "      <td>0.618576</td>\n",
       "      <td>0.585017</td>\n",
       "      <td>0.698804</td>\n",
       "      <td>0.529437</td>\n",
       "      <td>0.618596</td>\n",
       "      <td>0.642795</td>\n",
       "      <td>0.731954</td>\n",
       "      <td>0.496739</td>\n",
       "      <td>0.596454</td>\n",
       "      <td>0.551946</td>\n",
       "      <td>0.651661</td>\n",
       "      <td>1.530965</td>\n",
       "      <td>1.833626</td>\n",
       "      <td>1.779758</td>\n",
       "      <td>2.082419</td>\n",
       "      <td>0.510322</td>\n",
       "      <td>0.611209</td>\n",
       "      <td>0.593253</td>\n",
       "      <td>0.694140</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.045981</td>\n",
       "      <td>0.040349</td>\n",
       "      <td>0.708027</td>\n",
       "      <td>0.821813</td>\n",
       "      <td>0.821385</td>\n",
       "      <td>0.935172</td>\n",
       "      <td>0.653783</td>\n",
       "      <td>0.742942</td>\n",
       "      <td>0.708990</td>\n",
       "      <td>0.798149</td>\n",
       "      <td>1.361810</td>\n",
       "      <td>1.564756</td>\n",
       "      <td>1.530375</td>\n",
       "      <td>1.733321</td>\n",
       "      <td>0.680905</td>\n",
       "      <td>0.782378</td>\n",
       "      <td>0.765188</td>\n",
       "      <td>0.866660</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.038356</td>\n",
       "      <td>0.055770</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>0.096889</td>\n",
       "      <td>0.832373</td>\n",
       "      <td>0.946160</td>\n",
       "      <td>0.887580</td>\n",
       "      <td>1.001367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andy</td>\n",
       "      <td>dEcisi0n</td>\n",
       "      <td>0.121229</td>\n",
       "      <td>0.147608</td>\n",
       "      <td>0.268837</td>\n",
       "      <td>0.248161</td>\n",
       "      <td>0.369389</td>\n",
       "      <td>0.100553</td>\n",
       "      <td>0.068432</td>\n",
       "      <td>0.168985</td>\n",
       "      <td>0.170320</td>\n",
       "      <td>0.270873</td>\n",
       "      <td>0.101888</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.113149</td>\n",
       "      <td>0.089150</td>\n",
       "      <td>0.191038</td>\n",
       "      <td>0.077888</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>0.089852</td>\n",
       "      <td>0.135106</td>\n",
       "      <td>0.212994</td>\n",
       "      <td>0.123143</td>\n",
       "      <td>-0.055372</td>\n",
       "      <td>0.067771</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>0.134252</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.122867</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.248842</td>\n",
       "      <td>0.315322</td>\n",
       "      <td>0.125975</td>\n",
       "      <td>-0.023233</td>\n",
       "      <td>0.102741</td>\n",
       "      <td>0.055835</td>\n",
       "      <td>0.181810</td>\n",
       "      <td>0.079069</td>\n",
       "      <td>0.796225</td>\n",
       "      <td>0.283527</td>\n",
       "      <td>1.000683</td>\n",
       "      <td>0.958523</td>\n",
       "      <td>1.675678</td>\n",
       "      <td>0.099528</td>\n",
       "      <td>0.040504</td>\n",
       "      <td>0.142955</td>\n",
       "      <td>0.136932</td>\n",
       "      <td>0.239383</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.023033</td>\n",
       "      <td>0.075232</td>\n",
       "      <td>0.070302</td>\n",
       "      <td>0.091928</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.437822</td>\n",
       "      <td>0.418481</td>\n",
       "      <td>0.539710</td>\n",
       "      <td>0.181581</td>\n",
       "      <td>0.282134</td>\n",
       "      <td>0.259470</td>\n",
       "      <td>0.360023</td>\n",
       "      <td>0.101113</td>\n",
       "      <td>0.203001</td>\n",
       "      <td>0.224256</td>\n",
       "      <td>0.326144</td>\n",
       "      <td>0.079734</td>\n",
       "      <td>0.157623</td>\n",
       "      <td>0.146215</td>\n",
       "      <td>0.224103</td>\n",
       "      <td>0.133976</td>\n",
       "      <td>0.257119</td>\n",
       "      <td>0.259951</td>\n",
       "      <td>0.383093</td>\n",
       "      <td>0.225608</td>\n",
       "      <td>0.292089</td>\n",
       "      <td>0.304677</td>\n",
       "      <td>0.371158</td>\n",
       "      <td>1.038606</td>\n",
       "      <td>1.629787</td>\n",
       "      <td>1.613049</td>\n",
       "      <td>2.204230</td>\n",
       "      <td>0.173101</td>\n",
       "      <td>0.271631</td>\n",
       "      <td>0.268842</td>\n",
       "      <td>0.367372</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.088147</td>\n",
       "      <td>0.095986</td>\n",
       "      <td>0.090408</td>\n",
       "      <td>0.102217</td>\n",
       "      <td>0.429742</td>\n",
       "      <td>0.550971</td>\n",
       "      <td>0.507631</td>\n",
       "      <td>0.628859</td>\n",
       "      <td>0.271433</td>\n",
       "      <td>0.371986</td>\n",
       "      <td>0.394576</td>\n",
       "      <td>0.495128</td>\n",
       "      <td>0.168884</td>\n",
       "      <td>0.270772</td>\n",
       "      <td>0.235365</td>\n",
       "      <td>0.337253</td>\n",
       "      <td>0.269082</td>\n",
       "      <td>0.346970</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.472945</td>\n",
       "      <td>0.236717</td>\n",
       "      <td>0.359860</td>\n",
       "      <td>0.315786</td>\n",
       "      <td>0.438929</td>\n",
       "      <td>1.375858</td>\n",
       "      <td>1.900559</td>\n",
       "      <td>1.848414</td>\n",
       "      <td>2.373114</td>\n",
       "      <td>0.275172</td>\n",
       "      <td>0.380112</td>\n",
       "      <td>0.369683</td>\n",
       "      <td>0.474623</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.010310</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>0.095811</td>\n",
       "      <td>0.103347</td>\n",
       "      <td>0.101537</td>\n",
       "      <td>0.105305</td>\n",
       "      <td>0.519594</td>\n",
       "      <td>0.640822</td>\n",
       "      <td>0.642736</td>\n",
       "      <td>0.763965</td>\n",
       "      <td>0.339204</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.405685</td>\n",
       "      <td>0.506238</td>\n",
       "      <td>0.358232</td>\n",
       "      <td>0.460119</td>\n",
       "      <td>0.484206</td>\n",
       "      <td>0.586094</td>\n",
       "      <td>0.371823</td>\n",
       "      <td>0.449712</td>\n",
       "      <td>0.450892</td>\n",
       "      <td>0.528780</td>\n",
       "      <td>1.588853</td>\n",
       "      <td>1.990410</td>\n",
       "      <td>1.983520</td>\n",
       "      <td>2.385077</td>\n",
       "      <td>0.397213</td>\n",
       "      <td>0.497603</td>\n",
       "      <td>0.495880</td>\n",
       "      <td>0.596269</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.082677</td>\n",
       "      <td>0.095841</td>\n",
       "      <td>0.103057</td>\n",
       "      <td>0.116742</td>\n",
       "      <td>0.587365</td>\n",
       "      <td>0.708593</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.775074</td>\n",
       "      <td>0.528552</td>\n",
       "      <td>0.629104</td>\n",
       "      <td>0.654526</td>\n",
       "      <td>0.755079</td>\n",
       "      <td>0.460973</td>\n",
       "      <td>0.562861</td>\n",
       "      <td>0.540042</td>\n",
       "      <td>0.641930</td>\n",
       "      <td>1.576890</td>\n",
       "      <td>1.900559</td>\n",
       "      <td>1.848414</td>\n",
       "      <td>2.172083</td>\n",
       "      <td>0.525630</td>\n",
       "      <td>0.633520</td>\n",
       "      <td>0.616138</td>\n",
       "      <td>0.724028</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.063246</td>\n",
       "      <td>0.072966</td>\n",
       "      <td>0.065902</td>\n",
       "      <td>0.071798</td>\n",
       "      <td>0.776712</td>\n",
       "      <td>0.897941</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>1.023916</td>\n",
       "      <td>0.631293</td>\n",
       "      <td>0.731846</td>\n",
       "      <td>0.710362</td>\n",
       "      <td>0.810915</td>\n",
       "      <td>1.408006</td>\n",
       "      <td>1.629787</td>\n",
       "      <td>1.613049</td>\n",
       "      <td>1.834830</td>\n",
       "      <td>0.704003</td>\n",
       "      <td>0.814893</td>\n",
       "      <td>0.806525</td>\n",
       "      <td>0.917415</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.018494</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.102827</td>\n",
       "      <td>0.117447</td>\n",
       "      <td>0.135994</td>\n",
       "      <td>0.150615</td>\n",
       "      <td>0.879454</td>\n",
       "      <td>1.000683</td>\n",
       "      <td>0.958523</td>\n",
       "      <td>1.079751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject  Password    T2-D|0  T2-I|0+1  T2-PF|0+1  T2-RF|0+1  T2-NG|0+1  \\\n",
       "0    andy  dEcisi0n  0.112628  0.079001   0.191629   0.189652   0.302280   \n",
       "1    andy  dEcisi0n  0.102941  0.191321   0.294262   0.280651   0.383592   \n",
       "2    andy  dEcisi0n  0.114735  0.099664   0.214399   0.212517   0.327251   \n",
       "3    andy  dEcisi0n  0.113787  0.089431   0.203218   0.178590   0.292377   \n",
       "4    andy  dEcisi0n  0.121229  0.147608   0.268837   0.248161   0.369389   \n",
       "\n",
       "     T2-D|1  T2-I|1+2  T2-PF|1+2  T2-RF|1+2  T2-NG|1+2    T2-D|2  T2-I|2+3  \\\n",
       "0  0.110651  0.057247   0.167898   0.146393   0.257044  0.089146  0.056419   \n",
       "1  0.089330  0.089771   0.179101   0.169192   0.258522  0.079421  0.078084   \n",
       "2  0.112853  0.101198   0.214051   0.191127   0.303980  0.089929  0.035299   \n",
       "3  0.089159  0.057329   0.146488   0.157044   0.246203  0.099715  0.011228   \n",
       "4  0.100553  0.068432   0.168985   0.170320   0.270873  0.101888  0.011261   \n",
       "\n",
       "   T2-PF|2+3  T2-RF|2+3  T2-NG|2+3    T2-D|3  T2-I|3+4  T2-PF|3+4  T2-RF|3+4  \\\n",
       "0   0.145565   0.158604   0.247750  0.102185  0.044784   0.146969   0.169310   \n",
       "1   0.157506   0.156776   0.236197  0.078692  0.012010   0.090702   0.110938   \n",
       "2   0.125228   0.114423   0.204352  0.079124  0.004538   0.083662   0.122118   \n",
       "3   0.110943   0.078616   0.178331  0.067387  0.000992   0.068380   0.126114   \n",
       "4   0.113149   0.089150   0.191038  0.077888  0.011963   0.089852   0.135106   \n",
       "\n",
       "   T2-NG|3+4    T2-D|4  T2-I|4+5  T2-PF|4+5  T2-RF|4+5  T2-NG|4+5    T2-D|5  \\\n",
       "0   0.271495  0.124527 -0.045218   0.079309   0.043676   0.168202  0.088894   \n",
       "1   0.189630  0.098928 -0.022104   0.076824   0.022900   0.121828  0.045004   \n",
       "2   0.201242  0.117580 -0.054626   0.062954   0.023402   0.140982  0.078028   \n",
       "3   0.193501  0.125121 -0.035574   0.089547   0.044653   0.169775  0.080227   \n",
       "4   0.212994  0.123143 -0.055372   0.067771   0.011109   0.134252  0.066481   \n",
       "\n",
       "   T2-I|5+6  T2-PF|5+6  T2-RF|5+6  T2-NG|5+6    T2-D|6  T2-I|6+7  T2-PF|6+7  \\\n",
       "0  0.327517   0.416411   0.440134   0.529028  0.112617 -0.011089   0.101528   \n",
       "1  0.136034   0.181038   0.260071   0.305074  0.124036 -0.011227   0.112809   \n",
       "2  0.112980   0.191008   0.270615   0.348643  0.157635 -0.045640   0.111995   \n",
       "3  0.123010   0.203237   0.236368   0.316595  0.113358  0.010988   0.124347   \n",
       "4  0.122867   0.189348   0.248842   0.315322  0.125975 -0.023233   0.102741   \n",
       "\n",
       "   T2-RF|6+7  T2-NG|6+7    T2-D|7    T2-D|S    T2-I|S   T2-PF|S   T2-RF|S  \\\n",
       "0   0.054103   0.166720  0.065192  0.805840  0.508661  1.249309  1.201873   \n",
       "1   0.066895   0.190931  0.078121  0.696474  0.473890  1.092242  1.067423   \n",
       "2   0.033439   0.191074  0.079080  0.828963  0.253412  1.003296  0.967641   \n",
       "3   0.066195   0.179554  0.055207  0.743962  0.257405  0.946160  0.887580   \n",
       "4   0.055835   0.181810  0.079069  0.796225  0.283527  1.000683  0.958523   \n",
       "\n",
       "    T2-NG|S    T2-D|M    T2-I|M   T2-PF|M   T2-RF|M   T2-DT-M  T2-D|VAR  \\\n",
       "0  1.942520  0.100730  0.072666  0.178473  0.171696  0.277503  0.000355   \n",
       "1  1.685775  0.087059  0.067699  0.156035  0.152489  0.240825  0.000535   \n",
       "2  1.717525  0.103620  0.036202  0.143328  0.138234  0.245361  0.000767   \n",
       "3  1.576335  0.092995  0.036772  0.135166  0.126797  0.225191  0.000598   \n",
       "4  1.675678  0.099528  0.040504  0.142955  0.136932  0.239383  0.000531   \n",
       "\n",
       "   T2-I|VAR  T2-PF|VAR  T2-RF|VAR  T2-DT-VAR   T2-D|SD   T2-I|SD  T2-PF|SD  \\\n",
       "0  0.014530   0.012455   0.017236   0.014906  0.018849  0.120540  0.111601   \n",
       "1  0.006324   0.005446   0.009024   0.007353  0.023122  0.079522  0.073798   \n",
       "2  0.005016   0.003943   0.008473   0.006380  0.027687  0.070826  0.062790   \n",
       "3  0.003077   0.002773   0.004724   0.003611  0.024453  0.055474  0.052660   \n",
       "4  0.005660   0.004942   0.008451   0.006843  0.023033  0.075232  0.070302   \n",
       "\n",
       "   T2-RF|SD  T2-NG|SD  T3-I|0+2  T3-PF|0+2  T3-RF|0+2  T3-NG|0+2  T3-I|1+3  \\\n",
       "0  0.131286  0.122092  0.246899   0.359527   0.336045   0.448673  0.202812   \n",
       "1  0.094994  0.085747  0.370422   0.473363   0.449843   0.552784  0.247276   \n",
       "2  0.092047  0.079874  0.313715   0.428449   0.403644   0.518378  0.226426   \n",
       "3  0.068733  0.060089  0.235919   0.349706   0.335634   0.449421  0.168272   \n",
       "4  0.091928  0.082725  0.316593   0.437822   0.418481   0.539710  0.181581   \n",
       "\n",
       "   T3-PF|1+3  T3-RF|1+3  T3-NG|1+3  T3-I|2+4  T3-PF|2+4  T3-RF|2+4  T3-NG|2+4  \\\n",
       "0   0.313463   0.304997   0.415648  0.203387   0.292533   0.327914   0.417060   \n",
       "1   0.336607   0.325968   0.415298  0.168787   0.248208   0.267715   0.347136   \n",
       "2   0.339279   0.305550   0.418403  0.118961   0.208890   0.236541   0.326470   \n",
       "3   0.257432   0.235660   0.324819  0.079608   0.179323   0.204729   0.304444   \n",
       "4   0.282134   0.259470   0.360023  0.101113   0.203001   0.224256   0.326144   \n",
       "\n",
       "   T3-I|3+5  T3-PF|3+5  T3-RF|3+5  T3-NG|3+5  T3-I|4+6  T3-PF|4+6  T3-RF|4+6  \\\n",
       "0  0.124092   0.226277   0.212986   0.315171  0.371193   0.495719   0.483810   \n",
       "1  0.088834   0.167526   0.133838   0.212530  0.158934   0.257862   0.282970   \n",
       "2  0.067492   0.146616   0.145520   0.224644  0.136382   0.253962   0.294017   \n",
       "3  0.090540   0.157927   0.170767   0.238154  0.167663   0.292784   0.281021   \n",
       "4  0.079734   0.157623   0.146215   0.224103  0.133976   0.257119   0.259951   \n",
       "\n",
       "   T3-NG|4+6  T3-I|5+7  T3-PF|5+7  T3-RF|5+7  T3-NG|5+7    T3-I|S   T3-PF|S  \\\n",
       "0   0.608336  0.429045   0.517939   0.494237   0.583131  1.577429  2.205460   \n",
       "1   0.381898  0.248844   0.293848   0.326965   0.371969  1.283097  1.777413   \n",
       "2   0.411597  0.224975   0.303003   0.304054   0.382082  1.087950  1.680199   \n",
       "3   0.406143  0.247356   0.327584   0.302563   0.382791  0.989359  1.564756   \n",
       "4   0.383093  0.225608   0.292089   0.304677   0.371158  1.038606  1.629787   \n",
       "\n",
       "    T3-RF|S   T3-NG|S    T3-I|M   T3-PF|M   T3-RF|M   T3-NG|M  T3-I|VAR  \\\n",
       "0  2.159989  2.788020  0.262905  0.367577  0.359998  0.464670  0.013202   \n",
       "1  1.787299  2.281615  0.213849  0.296235  0.297883  0.380269  0.009506   \n",
       "2  1.689326  2.281574  0.181325  0.280033  0.281554  0.380262  0.008067   \n",
       "3  1.530375  2.105772  0.164893  0.260793  0.255063  0.350962  0.004933   \n",
       "4  1.613049  2.204230  0.173101  0.271631  0.268842  0.367372  0.007770   \n",
       "\n",
       "   T3-PF|VAR  T3-RF|VAR  T3-NG|VAR   T3-I|SD  T3-PF|SD  T3-RF|SD  T3-NG|SD  \\\n",
       "0   0.013524   0.011918   0.012390  0.114898  0.116292  0.109170  0.111309   \n",
       "1   0.010671   0.010554   0.012059  0.097501  0.103300  0.102732  0.109813   \n",
       "2   0.009921   0.007335   0.009725  0.089815  0.099605  0.085644  0.098617   \n",
       "3   0.006124   0.003888   0.005865  0.070237  0.078256  0.062350  0.076583   \n",
       "4   0.009213   0.008174   0.010448  0.088147  0.095986  0.090408  0.102217   \n",
       "\n",
       "   T4-I|0+3  T4-PF|0+3  T4-RF|0+3  T4-NG|0+3  T4-I|1+4  T4-PF|1+4  T4-RF|1+4  \\\n",
       "0  0.392464   0.505092   0.494649   0.607277  0.349780   0.460432   0.474307   \n",
       "1  0.527927   0.630868   0.606619   0.709560  0.337978   0.427309   0.436906   \n",
       "2  0.438943   0.553678   0.518067   0.632802  0.310088   0.422941   0.427668   \n",
       "3  0.346863   0.460649   0.414250   0.528037  0.236652   0.325811   0.361773   \n",
       "4  0.429742   0.550971   0.507631   0.628859  0.271433   0.371986   0.394576   \n",
       "\n",
       "   T4-NG|1+4  T4-I|2+5  T4-PF|2+5  T4-RF|2+5  T4-NG|2+5  T4-I|3+6  T4-PF|3+6  \\\n",
       "0   0.584958  0.282696   0.371842   0.371590   0.460736  0.540503   0.642688   \n",
       "1   0.526237  0.245610   0.325032   0.290614   0.370035  0.269872   0.348564   \n",
       "2   0.540521  0.181915   0.271844   0.259943   0.349872  0.258500   0.337624   \n",
       "3   0.450933  0.169155   0.268870   0.249383   0.349098  0.293777   0.361164   \n",
       "4   0.495128  0.168884   0.270772   0.235365   0.337253  0.269082   0.346970   \n",
       "\n",
       "   T4-RF|3+6  T4-NG|3+6  T4-I|4+7  T4-PF|4+7  T4-RF|4+7  T4-NG|4+7    T4-I|S  \\\n",
       "0   0.653120   0.755305  0.472721   0.597248   0.537913   0.662440  2.038165   \n",
       "1   0.393909   0.472600  0.271744   0.370672   0.349865   0.448793  1.653132   \n",
       "2   0.416135   0.495259  0.248377   0.365957   0.327456   0.445036  1.437822   \n",
       "3   0.407135   0.474522  0.292010   0.417131   0.347217   0.472338  1.338457   \n",
       "4   0.395056   0.472945  0.236717   0.359860   0.315786   0.438929  1.375858   \n",
       "\n",
       "    T4-PF|S   T4-RF|S   T4-NG|S    T4-I|M   T4-PF|M   T4-RF|M   T4-NG|M  \\\n",
       "0  2.577302  2.531579  3.070716  0.407633  0.515460  0.506316  0.614143   \n",
       "1  2.102444  2.077914  2.527226  0.330626  0.420489  0.415583  0.505445   \n",
       "2  1.952043  1.949269  2.463490  0.287564  0.390409  0.389854  0.492698   \n",
       "3  1.833626  1.779758  2.274927  0.267691  0.366725  0.355952  0.454985   \n",
       "4  1.900559  1.848414  2.373114  0.275172  0.380112  0.369683  0.474623   \n",
       "\n",
       "   T4-I|VAR  T4-PF|VAR  T4-RF|VAR  T4-NG|VAR   T4-I|SD  T4-PF|SD  T4-RF|SD  \\\n",
       "0  0.010269   0.011659   0.010465   0.011673  0.101338  0.107979  0.102301   \n",
       "1  0.013342   0.015268   0.014339   0.016180  0.115507  0.123565  0.119745   \n",
       "2  0.009241   0.011289   0.009832   0.011148  0.096131  0.106251  0.099158   \n",
       "3  0.004553   0.005661   0.004371   0.004312  0.067477  0.075238  0.066116   \n",
       "4  0.009180   0.010681   0.010310   0.011089  0.095811  0.103347  0.101537   \n",
       "\n",
       "   T4-NG|SD  T5-I|0+4  T5-PF|0+4  T5-RF|0+4  T5-NG|0+4  T5-I|1+5  T5-PF|1+5  \\\n",
       "0  0.108042  0.539433   0.652061   0.663960   0.776587  0.429089   0.539740   \n",
       "1  0.127200  0.618630   0.721570   0.717558   0.820498  0.414802   0.504133   \n",
       "2  0.105586  0.522604   0.637339   0.640185   0.754920  0.373042   0.485895   \n",
       "3  0.065666  0.415242   0.529029   0.540364   0.654150  0.326200   0.415359   \n",
       "4  0.105305  0.519594   0.640822   0.642736   0.763965  0.339204   0.439757   \n",
       "\n",
       "   T5-RF|1+5  T5-NG|1+5  T5-I|2+6  T5-PF|2+6  T5-RF|2+6  T5-NG|2+6  T5-I|3+7  \\\n",
       "0   0.517983   0.628634  0.699107   0.788253   0.811724   0.900870  0.642031   \n",
       "1   0.459806   0.549136  0.426649   0.506070   0.550685   0.630106  0.382682   \n",
       "2   0.451070   0.563923  0.372923   0.462852   0.530558   0.620487  0.370495   \n",
       "3   0.406427   0.495586  0.372392   0.472107   0.485751   0.585466  0.418123   \n",
       "4   0.405685   0.506238  0.358232   0.460119   0.484206   0.586094  0.371823   \n",
       "\n",
       "   T5-PF|3+7  T5-RF|3+7  T5-NG|3+7    T5-I|S   T5-PF|S   T5-RF|S   T5-NG|S  \\\n",
       "0   0.744216   0.707223   0.809408  2.309660  2.724270  2.700890  3.115500   \n",
       "1   0.461374   0.460803   0.539495  1.842762  2.193147  2.188852  2.539236   \n",
       "2   0.449619   0.449574   0.528698  1.639064  2.035705  2.071387  2.468027   \n",
       "3   0.485511   0.473330   0.540718  1.531958  1.902006  1.905872  2.275920   \n",
       "4   0.449712   0.450892   0.528780  1.588853  1.990410  1.983520  2.385077   \n",
       "\n",
       "     T5-I|M   T5-PF|M   T5-RF|M   T5-NG|M  T5-I|VAR  T5-PF|VAR  T5-RF|VAR  \\\n",
       "0  0.577415  0.681068  0.675222  0.778875  0.014143   0.012097   0.014836   \n",
       "1  0.460691  0.548287  0.547213  0.634809  0.011432   0.013771   0.014712   \n",
       "2  0.409766  0.508926  0.517847  0.617007  0.005660   0.007554   0.008083   \n",
       "3  0.382989  0.475501  0.476468  0.568980  0.001871   0.002198   0.003028   \n",
       "4  0.397213  0.497603  0.495880  0.596269  0.006835   0.009186   0.010621   \n",
       "\n",
       "   T5-NG|VAR   T5-I|SD  T5-PF|SD  T5-RF|SD  T5-NG|SD  T6-I|0+5  T6-PF|0+5  \\\n",
       "0   0.012798  0.118922  0.109987  0.121803  0.113126  0.618741   0.731369   \n",
       "1   0.016976  0.106919  0.117350  0.121293  0.130291  0.695453   0.798394   \n",
       "2   0.009883  0.075235  0.086911  0.089904  0.099412  0.585559   0.700294   \n",
       "3   0.004570  0.043251  0.046883  0.055029  0.067605  0.504790   0.618576   \n",
       "4   0.013629  0.082677  0.095841  0.103057  0.116742  0.587365   0.708593   \n",
       "\n",
       "   T6-RF|0+5  T6-NG|0+5  T6-I|1+6  T6-PF|1+6  T6-RF|1+6  T6-NG|1+6  T6-I|2+7  \\\n",
       "0   0.707635   0.820263  0.845500   0.956151   0.958117   1.068768  0.800635   \n",
       "1   0.740457   0.843398  0.595840   0.685171   0.719877   0.809207  0.539458   \n",
       "2   0.663586   0.778321  0.564050   0.676903   0.721685   0.834538  0.484918   \n",
       "3   0.585017   0.698804  0.529437   0.618596   0.642795   0.731954  0.496739   \n",
       "4   0.653846   0.775074  0.528552   0.629104   0.654526   0.755079  0.460973   \n",
       "\n",
       "   T6-PF|2+7  T6-RF|2+7  T6-NG|2+7    T6-I|S   T6-PF|S   T6-RF|S   T6-NG|S  \\\n",
       "0   0.889781   0.865827   0.954973  2.264876  2.577302  2.531579  2.844004   \n",
       "1   0.618879   0.617580   0.697001  1.830752  2.102444  2.077914  2.349606   \n",
       "2   0.574847   0.563997   0.653926  1.634526  1.952043  1.949269  2.266785   \n",
       "3   0.596454   0.551946   0.651661  1.530965  1.833626  1.779758  2.082419   \n",
       "4   0.562861   0.540042   0.641930  1.576890  1.900559  1.848414  2.172083   \n",
       "\n",
       "     T6-I|M   T6-PF|M   T6-RF|M   T6-NG|M  T6-I|VAR  T6-PF|VAR  T6-RF|VAR  \\\n",
       "0  0.754959  0.859101  0.843860  0.948001  0.014420   0.013338   0.016047   \n",
       "1  0.610251  0.700815  0.692638  0.783202  0.006239   0.008240   0.004331   \n",
       "2  0.544842  0.650681  0.649756  0.755595  0.002809   0.004450   0.006360   \n",
       "3  0.510322  0.611209  0.593253  0.694140  0.000290   0.000163   0.002114   \n",
       "4  0.525630  0.633520  0.616138  0.724028  0.004000   0.005324   0.004343   \n",
       "\n",
       "   T6-NG|VAR   T6-I|SD  T6-PF|SD  T6-RF|SD  T6-NG|SD  T7-I|0+6  T7-PF|0+6  \\\n",
       "0   0.015475  0.120082  0.115489  0.126678  0.124399  1.035152   1.147780   \n",
       "1   0.005865  0.078990  0.090774  0.065812  0.076585  0.876492   0.979433   \n",
       "2   0.008542  0.052999  0.066708  0.079748  0.092426  0.776567   0.891301   \n",
       "3   0.001628  0.017036  0.012778  0.045981  0.040349  0.708027   0.821813   \n",
       "4   0.005155  0.063246  0.072966  0.065902  0.071798  0.776712   0.897941   \n",
       "\n",
       "   T7-RF|0+6  T7-NG|0+6  T7-I|1+7  T7-PF|1+7  T7-RF|1+7  T7-NG|1+7    T7-I|S  \\\n",
       "0   1.147769   1.260397  0.947028   1.057679   1.012220   1.122871  1.982180   \n",
       "1   1.000528   1.103469  0.708650   0.797980   0.786771   0.876102  1.585142   \n",
       "2   0.934201   1.048936  0.676045   0.788898   0.755124   0.867977  1.452611   \n",
       "3   0.821385   0.935172  0.653783   0.742942   0.708990   0.798149  1.361810   \n",
       "4   0.902687   1.023916  0.631293   0.731846   0.710362   0.810915  1.408006   \n",
       "\n",
       "    T7-PF|S   T7-RF|S   T7-NG|S    T7-I|M   T7-PF|M   T7-RF|M   T7-NG|M  \\\n",
       "0  2.205460  2.159989  2.383269  0.991090  1.102730  1.079995  1.191634   \n",
       "1  1.777413  1.787299  1.979570  0.792571  0.888706  0.893650  0.989785   \n",
       "2  1.680199  1.689326  1.916914  0.726306  0.840099  0.844663  0.958457   \n",
       "3  1.564756  1.530375  1.733321  0.680905  0.782378  0.765188  0.866660   \n",
       "4  1.629787  1.613049  1.834830  0.704003  0.814893  0.806525  0.917415   \n",
       "\n",
       "   T7-I|VAR  T7-PF|VAR  T7-RF|VAR  T7-NG|VAR   T7-I|SD  T7-PF|SD  T7-RF|SD  \\\n",
       "0  0.003883   0.004059   0.009187   0.009457  0.062313  0.063711  0.095848   \n",
       "1  0.014085   0.016462   0.022846   0.025848  0.118682  0.128306  0.151149   \n",
       "2  0.005052   0.005243   0.016034   0.016373  0.071080  0.072410  0.126627   \n",
       "3  0.001471   0.003110   0.006316   0.009388  0.038356  0.055770  0.079475   \n",
       "4  0.010573   0.013794   0.018494   0.022685  0.102827  0.117447  0.135994   \n",
       "\n",
       "   T7-NG|SD  T8-I|0+7  T8-PF|0+7  T8-RF|0+7  T8-NG|0+7  \n",
       "0  0.097245  1.136681   1.249309   1.201873   1.314501  \n",
       "1  0.160773  0.989301   1.092242   1.067423   1.170363  \n",
       "2  0.127957  0.888561   1.003296   0.967641   1.082376  \n",
       "3  0.096889  0.832373   0.946160   0.887580   1.001367  \n",
       "4  0.150615  0.879454   1.000683   0.958523   1.079751  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import unseen data\n",
    "pred_df = pd.read_csv(ACTUAL_DATASET_PATH)\n",
    "pred_df.head()\n",
    "# pred_df = df_drop(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "837b9992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################\n",
    "# # check for class validity # #\n",
    "################################\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"Subject\", data=pred_df).set_title(\"Class Validity\")\n",
    "\n",
    "# remove missing values if available\n",
    "pred_df = pred_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b061d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['andy', 'azfar', 'bryce', 'chris', 'cy', 'gerald', 'ken', 'qk', 'sz', 'vale', 'ye', 'ys']\n"
     ]
    }
   ],
   "source": [
    "pred_dataset = pred_df.values\n",
    "results = pred_dataset[:,CLASSES_COL_NUM]\n",
    "\n",
    "# # divide data into features X\n",
    "# pred_row = pred_dataset[:,3:].astype(float)\n",
    "\n",
    "########################\n",
    "# # predict all rows # #\n",
    "########################\n",
    "pred_row=pred_df.iloc[:,FEATURES_COL_NUM:]\n",
    "\n",
    "#################################\n",
    "# # predict more than one row # #\n",
    "#################################\n",
    "\n",
    "# pred_row=pred_df.iloc[46:54,FEATURES_COL_NUM:]\n",
    "# print(pred_row)\n",
    "\n",
    "############################\n",
    "# # predict a single row # #\n",
    "############################\n",
    "\n",
    "# pred_row=pred_df.iloc[11:12,FEATURES_COL_NUM:]\n",
    "\n",
    "##################\n",
    "# # shape data # #\n",
    "##################\n",
    "pred_row = pred_row.values.tolist()\n",
    "pred_arr = np.asarray(pred_row, dtype=np.float32)\n",
    "pred_arr = np.reshape(pred_arr, (pred_arr.shape[0], TIMESTEPS, pred_arr.shape[1]))\n",
    "\n",
    "Y = CLASS_LIST\n",
    "print(Y)\n",
    "Y = np.asarray(Y)\n",
    "Y = Y.reshape(-1, 1)\n",
    "lb = LabelBinarizer().fit(Y)\n",
    "Y = lb.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad543869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Results Prediction    Accuracy\n",
      "0     andy       andy    0.975579\n",
      "1     andy       andy   0.9744418\n",
      "2     andy       andy   0.9739439\n",
      "3     andy       andy   0.9690893\n",
      "4     andy       andy   0.9754833\n",
      "5    azfar      azfar   0.8913001\n",
      "6    azfar      azfar   0.8429772\n",
      "7    azfar      azfar  0.89076513\n",
      "8    azfar      chris  0.46672392\n",
      "9    azfar      chris   0.8074221\n",
      "10   bryce         cy   0.7150306\n",
      "11   bryce      bryce   0.9425983\n",
      "12   bryce      bryce  0.94184434\n",
      "13   bryce      bryce   0.8214919\n",
      "14   bryce      bryce   0.9388618\n",
      "15   chris      chris  0.43119973\n",
      "16   chris      chris  0.80732894\n",
      "17   chris      chris    0.807287\n",
      "18   chris      chris   0.8022468\n",
      "19   chris      chris   0.5578151\n",
      "20      cy         cy  0.82022697\n",
      "21      cy         cy   0.8660573\n",
      "22      cy         cy   0.8641271\n",
      "23      cy         cy   0.8577295\n",
      "24      cy         cy   0.8070994\n",
      "25  gerald     gerald   0.4809165\n",
      "26  gerald     gerald  0.54180014\n",
      "27  gerald        ken   0.4169865\n",
      "28  gerald         qk   0.5383703\n",
      "29  gerald         qk   0.3609225\n",
      "30     ken         qk  0.30534008\n",
      "31     ken        ken  0.42034075\n",
      "32     ken        ken  0.35968217\n",
      "33     ken        ken  0.34538692\n",
      "34     ken      chris   0.5529643\n",
      "35      qk         qk   0.5400752\n",
      "36      qk         qk   0.5086886\n",
      "37      qk         qk   0.5392719\n",
      "38      qk         ys   0.7953947\n",
      "39      qk         qk  0.49298307\n",
      "40      sz         sz  0.45842415\n",
      "41      sz      chris   0.3836927\n",
      "42      sz         qk  0.49931002\n",
      "43      sz         sz   0.4537722\n",
      "44      sz         sz  0.32563958\n",
      "45    vale      bryce  0.58560973\n",
      "46    vale      bryce   0.6091882\n",
      "47    vale         cy  0.86011094\n",
      "48    vale       vale   0.9207774\n",
      "49    vale         cy  0.87168705\n",
      "50      ye         ye  0.77287155\n",
      "51      ye         ye   0.7722579\n",
      "52      ye         ye  0.77419174\n",
      "53      ye         ye   0.7726172\n",
      "54      ye     gerald   0.5698267\n",
      "55      ys         ys   0.8334244\n",
      "56      ys         ys  0.82918817\n",
      "57      ys         ys   0.8345764\n",
      "58      ys         ys  0.83247524\n",
      "59      ys         ys   0.8414145\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# # get prediction and its label # #\n",
    "####################################\n",
    "\n",
    "pred_proba = model.predict(pred_arr)\n",
    "\n",
    "# pred_proba = np.sum(pred_proba, axis=0)\n",
    "# pred_proba = np.reshape(pred_proba, (1, 9))\n",
    "\n",
    "pred = lb.inverse_transform(pred_proba)\n",
    "acc = np.max(pred_proba, axis=1)\n",
    "\n",
    "pred_results = np.column_stack((pred, acc))\n",
    "pred_results = np.column_stack((results, pred_results))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.DataFrame(data=pred_results, index=None, columns=['Results', 'Prediction', 'Accuracy'])\n",
    "# df = pd.DataFrame(data=pred_results, index=None, columns=['Prediction', 'Accuracy'])\n",
    "print(df)\n",
    "\n",
    "# =IF(EXACT(B2, C2), \"Match\", \"Nope\")\n",
    "\n",
    "df.to_csv(RESULT_NAME)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7d334f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d2798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8af20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
